{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1><b>RAG-Fin-GPT : An AI Tool for Financial Research and Analytics</b></h1></center>\n",
    "\n",
    "This is an AI solution for performing in-depth financial research and analysis. This system is based on Retrieval-Augmented Generation (RAG), utilizing a locally run Llama2-7b-chat LLM, developed by Meta. This system uses completely open-source components and takes care of the data security considerations as well, by hosting everything on a local system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import sys\n",
    "import torch\n",
    "import nest_asyncio \n",
    "nest_asyncio.apply()\n",
    "\n",
    "from huggingface_hub import login\n",
    "from llama_index.llms.llama_cpp import LlamaCPP\n",
    "#from llama_index.core.llms.utils import messages_to_prompt, completion_to_prompt\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "\n",
    "from llama_index.core import Settings\n",
    "\n",
    "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex, set_global_tokenizer, StorageContext, load_index_from_storage\n",
    "\n",
    "from llama_index.core import download_loader\n",
    "from llama_index.readers.file import PyMuPDFReader\n",
    "from llama_index.readers.web import NewsArticleReader\n",
    "\n",
    "from llama_index.core.node_parser import SemanticSplitterNodeParser\n",
    "from llama_index.core.ingestion import IngestionPipeline\n",
    "\n",
    "from llama_index.retrievers.bm25 import BM25Retriever\n",
    "from llama_index.core.retrievers import BaseRetriever, VectorIndexRetriever\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core.postprocessor import SentenceTransformerRerank\n",
    "from llama_index.core.postprocessor import SimilarityPostprocessor\n",
    "\n",
    "from llama_index.core import QueryBundle\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "\n",
    "from llama_index.core.response.notebook_utils import display_response, display_source_node, display_query_and_multimodal_response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to C:\\Users\\rck05\\.cache\\huggingface\\token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "hf_token = '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'\n",
    "login(token=hf_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    stream = sys.stdout,\n",
    "    level = logging.INFO\n",
    ")\n",
    "logging.getLogger().addHandler(\n",
    "    logging.StreamHandler(\n",
    "        stream = sys.stdout\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'Llama2-7b'\n",
    "model_path = r\"D:\\0-VARAD-DESHMUKH\\models\\llama-2-7b-chat.Q6_K.gguf\"\n",
    "max_new_tokens = 2048\n",
    "context_window = 4096\n",
    "\n",
    "system_prompt = '''\n",
    "You are an experienced investment and financial research analyst, who always generates responses based only on the source documents given./\n",
    "You cite the relevant source documents properly at the end of the response or in the format 'According to <source>,'. You include the numerical figures/\n",
    "from the source documents to elucidate your response, but NEVER HALLUCINATE ANY INFORMATION. If any details are missing from the source documents,/\n",
    "you explicitly state so, rather than making up the missing information. Your responses are well-cited and credible, apt to be included in research reports.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 19 key-value pairs and 291 tensors from D:\\0-VARAD-DESHMUKH\\models\\llama-2-7b-chat.Q6_K.gguf (version GGUF V2)\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = LLaMA v2\n",
      "llama_model_loader: - kv   2:                       llama.context_length u32              = 4096\n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 11008\n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 32\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000001\n",
      "llama_model_loader: - kv  10:                          general.file_type u32              = 18\n",
      "llama_model_loader: - kv  11:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  12:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  14:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  15:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.eos_token_id u32              = 2\n",
      "llama_model_loader: - kv  17:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  18:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q6_K:  226 tensors\n",
      "llm_load_vocab: special tokens definition check successful ( 259/32000 ).\n",
      "llm_load_print_meta: format           = GGUF V2\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32000\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: n_ctx_train      = 4096\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 32\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 1\n",
      "llm_load_print_meta: n_embd_k_gqa     = 4096\n",
      "llm_load_print_meta: n_embd_v_gqa     = 4096\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-06\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 11008\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_yarn_orig_ctx  = 4096\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: model type       = 7B\n",
      "llm_load_print_meta: model ftype      = Q6_K\n",
      "llm_load_print_meta: model params     = 6.74 B\n",
      "llm_load_print_meta: model size       = 5.15 GiB (6.56 BPW) \n",
      "llm_load_print_meta: general.name     = LLaMA v2\n",
      "llm_load_print_meta: BOS token        = 1 '<s>'\n",
      "llm_load_print_meta: EOS token        = 2 '</s>'\n",
      "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
      "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
      "llm_load_tensors: ggml ctx size =    0.11 MiB\n",
      "llm_load_tensors:        CPU buffer size =  5272.34 MiB\n",
      "....................................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 4096\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_kv_cache_init:        CPU KV buffer size =  2048.00 MiB\n",
      "llama_new_context_with_model: KV self size  = 2048.00 MiB, K (f16): 1024.00 MiB, V (f16): 1024.00 MiB\n",
      "llama_new_context_with_model:        CPU input buffer size   =    17.02 MiB\n",
      "llama_new_context_with_model:        CPU compute buffer size =   288.00 MiB\n",
      "llama_new_context_with_model: graph splits (measure): 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text-generation model \"Llama2-7b\" loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 0 | VSX = 0 | MATMUL_INT8 = 0 | \n",
      "Model metadata: {'general.name': 'LLaMA v2', 'general.architecture': 'llama', 'llama.context_length': '4096', 'llama.rope.dimension_count': '128', 'llama.embedding_length': '4096', 'llama.block_count': '32', 'llama.feed_forward_length': '11008', 'llama.attention.head_count': '32', 'tokenizer.ggml.eos_token_id': '2', 'general.file_type': '18', 'llama.attention.head_count_kv': '32', 'llama.attention.layer_norm_rms_epsilon': '0.000001', 'tokenizer.ggml.model': 'llama', 'general.quantization_version': '2', 'tokenizer.ggml.bos_token_id': '1', 'tokenizer.ggml.unknown_token_id': '0'}\n"
     ]
    }
   ],
   "source": [
    "# the model\n",
    "llm = LlamaCPP(\n",
    "    model_path = model_path,\n",
    "    temperature = 0,\n",
    "    max_new_tokens = max_new_tokens,\n",
    "    context_window = context_window,\n",
    "    generate_kwargs = {},\n",
    "    model_kwargs = {\n",
    "        'load_in_8bit' : True,\n",
    "        'n_gpu_layers' : -1\n",
    "    },\n",
    "    system_prompt = system_prompt,\n",
    "    #messages_to_prompt=messages_to_prompt,\n",
    "    #completion_to_prompt=completion_to_prompt,\n",
    "    verbose = True\n",
    ")\n",
    "\n",
    "print('Text-generation model \"Llama2-7b\" loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_model = r'meta-llama/Llama-2-7b-chat-hf'\n",
    "hf_token = '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'\n",
    "set_global_tokenizer(\n",
    "    AutoTokenizer.from_pretrained(\n",
    "        pretrained_model_name_or_path=tokenizer_model,\n",
    "        token=hf_token\n",
    "    ).encode\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding model found in cache.\n",
      "Model name:  WhereIsAI/UAE-Large-V1 \n",
      "Model Directory:  C:\\Users\\rck05\\.cache\\huggingface\\hub\\models--WhereIsAI--UAE-Large-V1\\snapshots\\82f6ace7a8954c012dd2ae05e2604fbc9007205b\n"
     ]
    }
   ],
   "source": [
    "embed_model_path = r\"C:\\Users\\rck05\\.cache\\huggingface\\hub\\models--WhereIsAI--UAE-Large-V1\\snapshots\\82f6ace7a8954c012dd2ae05e2604fbc9007205b\"\n",
    "embed_model_name = 'WhereIsAI/UAE-Large-V1'\n",
    "\n",
    "if not os.path.exists(embed_model_path):\n",
    "    embed_model = HuggingFaceEmbedding(embed_model_name)\n",
    "    print('Embedding model not found in cache. Downloading and creating one.!')\n",
    "else:\n",
    "    embed_model = HuggingFaceEmbedding(embed_model_path) \n",
    "    print('Embedding model found in cache.')\n",
    "\n",
    "print('Model name: ', embed_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Settings done.\n"
     ]
    }
   ],
   "source": [
    "Settings.llm = llm\n",
    "Settings.embed_model = embed_model\n",
    "#Settings.chunk_size = 512\n",
    "Settings.context_window = context_window\n",
    "Settings.num_output = max_new_tokens\n",
    "\n",
    "print('Settings done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pdfs\n",
    "files = [\n",
    "    r\"D:\\0-VARAD-DESHMUKH\\Files\\data\\meta-10k-2023.pdf\",\n",
    "    r\"D:\\0-VARAD-DESHMUKH\\Files\\data\\q3-2023.pdf\"\n",
    "]\n",
    "\n",
    "pdfs = []\n",
    "for file in files:\n",
    "    pdf = PyMuPDFReader().load_data(\n",
    "        file_path=file,\n",
    "        metadata=True\n",
    "    )\n",
    "    pdfs += pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# News Articles\n",
    "news_articles = [\n",
    "    r'https://www.indiatvnews.com/technology/news/meta-collaborates-with-ncmec-to-extend-take-it-down-program-for-teenagers-2024-02-07-915677',\n",
    "    r'https://www.msn.com/en-in/money/news/meta-to-label-ai-generated-images-across-social-media-platforms-details-here/ar-BB1hTNrL',\n",
    "    r'https://www.msn.com/en-in/money/other/meta-announces-plans-to-combat-deepfakes-and-ai-generated-content-on-facebook-instagram-threads-ahead-of-key-elections/ar-BB1hTfPt',\n",
    "    r'https://timesofindia.indiatimes.com/gadgets-news/20-years-of-facebook-meta-added-more-than-one-tcs-in-a-day-to-its-value/articleshow/107460150.cms',\n",
    "    r'https://www.nytimes.com/2024/02/01/technology/meta-profit-report.html',\n",
    "    r'https://www.msn.com/en-in/money/markets/meta-platforms-shatters-records-with-a-196-bn-surge-in-stock-market-value/ar-BB1hMN6e',\n",
    "]\n",
    "\n",
    "news_reader = NewsArticleReader(use_nlp=False)\n",
    "news = news_reader.load_data(\n",
    "    news_articles\n",
    ")\n",
    "\n",
    "# change 'publish_date' metadata to string for JSON serialization\n",
    "for i in range(len(news)):\n",
    "    news[i].metadata['publish_date'] = str(news[i].metadata['publish_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Websites\n",
    "WholeSiteReader = download_loader('WholeSiteReader')\n",
    "\n",
    "prefix = r'https://about.meta.com'\n",
    "base_url = r'https://about.meta.com/company-info/'\n",
    "max_depth = 1\n",
    "\n",
    "scraper = WholeSiteReader(\n",
    "    prefix=prefix,\n",
    "    max_depth=max_depth\n",
    ")\n",
    "\n",
    "websites = scraper.load_data(\n",
    "    base_url=base_url\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Static htmls\n",
    "SimpleWebPageReader = download_loader('SimpleWebPageReader')\n",
    "\n",
    "urls = [\n",
    "    r'https://www.sec.gov/Archives/edgar/data/1326801/000132680124000012/meta-20231231.htm'\n",
    "]\n",
    "loader = SimpleWebPageReader()\n",
    "\n",
    "htmls = loader.load_data(\n",
    "    urls=urls\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# other files - docx, etc.\n",
    "document_directory = r\"D:\\0-VARAD-DESHMUKH\\Files\\data\"\n",
    "\n",
    "others = SimpleDirectoryReader(\n",
    "    document_directory,\n",
    "    filename_as_id=True\n",
    ").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenating all the sources into Document objects\n",
    "documents = pdfs #+ news + websites + htmls + others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94d7ab22314b41eab9b903367f51cfc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing nodes:   0%|          | 0/219 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13cf78e5da5841ccbb359444095f2cca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f960c78bd52424f8a588b3e92f7af34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56ac5e8cbc574878b90cb9840cbcf3fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f216367798c94019a067d74d8ca05131",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2527d79f1ea64725bf8846aa24a2da06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc9b91c8957a47bbb7153035587a0de1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/29 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36f7c21264754614b4006bda5a6166f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b5790fc9c484545b147f7c3240810fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21bc83d3d62e41568f7b4275e15d9004",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09fb5ab526ca4b7098aa851a5021cf6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a830bf2dcfc0474d887e12ef8524fcdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caff2e114ea749bdae9d7868a8506335",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2d92babd4a24746b421760e949e7dab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/26 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f5b139cbac84cacb4a4235ac843f225",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad0cce787ca14e939cb2958a6305b633",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fe34ee1cfaa499398fb145b71659ac3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "536223fb568f44f58a841069e846886e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "561dede932aa4535ab22f7b863a2d18d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62277634a3ca4817b250537428b1862e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cccec8507514dc1a9864004160d126d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a203ccd1f074c79a3bd98391ae69c07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "908522349f8440b78be30ccf2039a35e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a81cb90cefd042ba91966366ae28d6d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0d9f7987a9948f69eaede9a8fa9974a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf188b43ad9e4e07ba9857c82fff7534",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e663e8c7b051470c9ef017989b3937c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6d6036775ee476393ad570a82d9cd72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20586876afdd4e6286630f54e0d417cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf992c258f9b4167a9600e0a0c0e7e1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f5e4fb309144b1fa8a4f25c48ad8b7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab68ff454d7e4f2e84604977aed02f0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb0678cc3e244eb0adbd3d3744f271ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b64cb77227054af59165077b38591fe1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab10e65f4d0241e7b7cc2a011b617c3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40df74da8e9c4f6e95949ffc9af12a1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba7bec77f2274e51be56a0c8ad8cac83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d88888b3d9bc4f2fa0c90c5d83edb3f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d00dc86f96f42dbaf8effdd0b81a678",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be8a3865e71c410b9a727bcb7241f779",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0e2f1953d7c4279a1942c22264f1a60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f0840c6ce5e48f2b7ebebaa1d94f84c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe22c8c6b24143aab7842441151465d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9520095b0b2d4602b93e65dd9cf44e04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d54c2d7e7c8e491eb150ca1f55e878ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f506bba202ba4c4996340975635fdd9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "720fb38d79a44a69af610867f03a8152",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4178487db7cf40c2a6d0142a3ca3418f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9868988182a457b91bccb8c3bdb85b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bab8bedceed84ca98af2da116ab28f2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e50b05a31df14a25806a8823bbeda7d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19fe0c9ab49a4910afc11d0a4ed48209",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09b0c5e243ca46b584e3c5468a69e003",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edf593d34966452b91af0e9e9e0ab751",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76ae312e12a941cba94cdcd9c5af2255",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a00f200b4517493082eaadaa228b3f21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "470acca97559415792257015f1f4d88d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6af6f979d674e33a0381b7305a70580",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43778366792d4e4fba7c796b182fd3e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89543a1ed75841dd85ec0d9e1b335293",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e78d0a1b630b463a941612d7df49e679",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e650bf52a4d4aad9beeca5049d289fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "902a56b075754a4eaeff7b67135cbab0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ceaba5f4074848ac9b2eb2873cd78729",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9afddeffa4fb4a3fbd01397d88cf9252",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42e4e659fa6a4b1f8e92fa3c405b4952",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5963a4b2e7c0470a9daa510761f5532a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ef841a26110488fa810cf081a3f2bc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/34 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3edfe10d4d944831a0c4cd77bf6b147b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "612b3750f4dc441cbdb394a45475be9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a31ad2e778fa492eabad535c9e8b657d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eeb9b467454d46ac9be464f386757015",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d588416516aa4a4cbef05ca02fce85c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "077475ab94cc4b8980dee3b6c8339132",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d872f929241644ad814760e9924d2811",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0994f6d045740439e2941b56862f417",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "815c4cf01a5b412e92c4764a09491929",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99f387f4d6c0481a9d898884c6153225",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1b45b3b79224788a6ee826d373fc442",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab903728c60a413e8db1e11b4b6d73fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5cb9d05f2784277b8ed238436a45fc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca69228c9d10449cada140ca1bb47efc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24da7c7973fe41d4a4779414481a7291",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9868653557f249da8b5992d8b78ac242",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4aed5fb00304296bcdad901c27bc0ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a74be890b9c34199afea046eeaab8b1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbecf3842f674c31bdd90d3ad2e3d0bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae5fdb254dbc4db2ab828f35091238ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0522bd496704355b951685b3540633e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d1af92528004557ba2c9e36fa508c8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6a7374eeeed4263ad72faefc7da7335",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a438f1e186344c8ae82d415983ba0fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17ab247e71834ee8bbeaaacec7bfe2cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca390bcb286e4fa1af00f8206ed68233",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cca703c042c423198c00a8342ef1bf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0308b4f56954c1f944b796feb6c5513",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3fffa75bd6944b1b19e603f8055dafb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e60879752af4c76b043bc5d65ed3fcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe0cfaa5512140cba7757171ab69d2aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/34 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fccf283b3db4959a6738b25ccf71ab4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39d2d9cde5d34b9f9be1f1936b94c1d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9616b2d5992b434cb2171be2dd398d12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a06faa3619047d0b1c003e747f844fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de77da0dbb124d9bbfa57b074126ac71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "995b33178c8f427493140c64f33058d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bf32a2e6e604707b174c6e2c00d0659",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54260bee93ff470b8e858fa60d83980c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "579e002918404e7893a691dad82ddac8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "866b7ee9e04e4041b531f42e1924bd67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a433248e7d174e5fab522c83f06ebf33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5a5c19b28ff400abf80f0703c3662c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "587df5651dc243c5acd78c8573de93a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "feb37bf316054e3aa009802f1400ba54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "859732ef76414283863b1fcddde3d9a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0335510a4e04337a132e580101cc77a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f17a65683ab4bc6b7a86f53130060cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b0bbb4570e344b296d2b74f4292ef64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb1c234b86264bac8c360ad81b9efeb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "154a12975fc44b3886d6b20357fb9191",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "beb937c0da9449dbadf9b255d2e6a987",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7409c78455894e99b39f6771f449945f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "672e3e5b3b3c453999b7d0088d34bdcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a57b10a3ca314cac8d2de91b8284d940",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/26 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96511ea42e694d9587674e3234bc81aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d7c2ee7742d470fa4edaf51f53f017e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9340734692f54db1800da1ebea2f0c23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a73010c1186c43a084551f577f705c51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92ee000d730a4a52a2a41338f49ed11d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa614506b76d4e13b6bfefbde89b700a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dcef89b064a48b6b5ccc0f38efdf363",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6e6e34d137642d9a5824bf7cfdd99ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "348c98b2746b459b97317fd6c5dc3f2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e58d0274e09f4eff949dc3e3a38fea21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cd3f5a05c5845b08c654f9c9f791683",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff449611e0f94c75995c7ee27f620b92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fed91b55b17c4f5dbeeb724c45faca6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dea7e11d75e747e0be09e6840ae4ed6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88428ad4c3c94b72b31ec5977c1b7e30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30d520bea1f942fa873f8d7792262d17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18aef5968d744b129bb8c753b3ffea17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf3079d3631945e6824fd19a837c2b61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2436767a270403b9d929a2c3eaa1442",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4800f78cd92643eabc38138772440d18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6537c2c2a899440f8127b6882e13b8a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eeab5b96361b410a81eb0c652eae7dd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd595fe121634466a4759102475fbe43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "733a3639e0834469bd715f4877461df5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41f4c98ae3174eb48a3406845360d540",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd3e73a9df2e4968ac880e62b64698fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c40a83301fed43dd80cf32df25692ae7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec9bedae9a6c462a841f7d22388dfe22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4ab3a40413644b09890fc44ec45d34d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c757baff690431594f22ba0b6c891fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8152259d582c46f6b94f4075067d8a34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/29 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f03048e21c040f0a1a2890c3528f6a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b9cd50e60a74305bcb185f61a8f047a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccc37e16b2ab4cc9b64c2d34bfaa0541",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "215c2512562b4deba83cfc10febed6ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f20104eb864a41579a8e3c9498b59a93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21e00de1861e4a53b8eff87e2e164fe9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5157c316a8264032b652ee41597f220d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ae68e899ffc4e2ba2009d7f47e89b20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aafcf48059934da48052c5a6281c7907",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6e27044ba1c4907ab41bfb60d4fcbb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b530b5a0264e425d9205bc70f720fc30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "660430bee3fb4561b34ef6ed39298965",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8e8863e96534c9686f5a53295dbc46e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65b7974123784a319c7dd4687ef42cc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f13f908bdbd3483b87953a9d35f5cd64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdb84e678d5843f78fa759953784cb2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68b3a148e4c24e1c8e94107a97bfcd98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e3dbd6fd37a448d87e7dd5db071960a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c54748a681b41a6bfb5f1906d13451a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11a8c2787077468a819f321d45f1e284",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a2afd493fd0441ebd453297fe11089d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c198321e7564dcd860e9fc4f163a31f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "296c14b5c636481c9851c308d591a7cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ad9ee95b89a428e89786c006a41cef1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9314871c742941388c197fbc00f04bc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a851173d8bb1484c86e2cbefb4440260",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "671258f908054940a8d72718ced57ecb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fabface5e99645ce90d85c01a36fee3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c4e7fb233834239ae5c157ee5879a27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57bb091f9889487c9ebb28cfcccd6966",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe4a47e1bd144930a3fcfabd31de263c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d65e3b3930543cc9c0d61188f1c58f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34152676bde24d92816160953d8801f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0341fc511bea4c3486c479add477cd8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50b17c2fbee041fd87fa2b15cf0656da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f69a3c2861af4174b20313f289627b98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c33b64ad51f24e3ea8d84909f60f4533",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d86f00fa74fe406c8cd6ed1c3e1e8223",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b599cf8fe4044330996e906cd1b5451c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26bfbdafb25f432b994f0971315780ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99c6daf03ef946a495b8a7457d3a26ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eee547f4ba08431ca6c186c9b6227368",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da8c6d7b3db247d593d05af6fdf56cae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "386c094d2dc74810bdbf0f475423e0ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d18e0b08842416cbc0d9d140225ee4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8af1b2bc3fa64eb9a08a0e34a35ce7e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "378b01c9af6e457a98a3454335ab0977",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc84f97e2ea14dd6bb32ae3730cb9841",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a1f3a9efb4f4ab6a70c25d225ffee71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5380d25c5214cee83ae50a87c890302",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec7bd404bc82421c8b7509dc209bd0b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/26 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "080157e9325d48f598680cf7e8b3ec50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3a31044062841d9966f0cfe7796cc0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "629f772bb1e94b7f9af1cdb7b69c7af5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42340fcb006f46a186291146fe186c57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cab296c2f00c416388f45b52da9fd5f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca0646ea6f6d420caca12041994ac45d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8f331a648fb4c96bc112973a5ee6036",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efb337c461ab4df193615bd5262a7ad8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "169eb4349c434476b42b717f83edf7b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1311f9deb655413b862bcc36e727e7d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fc4b2853e3741818e1796ba6866327f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e993b428c9744a17ac9efb18588eebff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abfe9e5292d94f289bf3131e88f68452",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c48fd195051f4fde84c1c4155ab169b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b530e2c5cd3748838482daf4271aba61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7783c320d35b4b08925d604eef3ec70a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/399 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'\\n# load the existing index\\nstorage_context = StorageContext.from_defaults(persist_dir=PERSIST_DIR)\\nindex = load_index_from_storage(storage_context)\\nnodes = list(index.docstore.docs.values())\\n'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splitter = SemanticSplitterNodeParser(\n",
    "    buffer_size=3,\n",
    "    breakpoint_percentile_threshold=95,\n",
    "    embed_model=embed_model,\n",
    "    include_prev_next_rel=True,\n",
    "    include_metadata=True\n",
    ")\n",
    "    \n",
    "embedding = HuggingFaceEmbedding(embed_model_name)\n",
    "pipeline = IngestionPipeline(\n",
    "transformations=[splitter, embedding]\n",
    ")\n",
    "\n",
    "nodes = pipeline.run(\n",
    "    documents=documents,\n",
    "    in_place=False,\n",
    "    show_progress=True\n",
    ")\n",
    "\n",
    "storage_context = StorageContext.from_defaults()\n",
    "storage_context.docstore.add_documents(nodes)\n",
    "pdf_index = VectorStoreIndex(\n",
    "    nodes,\n",
    "    storage_context=storage_context\n",
    ")\n",
    "\n",
    "# store it for later\n",
    "PERSIST_DIR = './storage-dt'\n",
    "pdf_index.storage_context.persist(persist_dir=PERSIST_DIR)\n",
    "\n",
    "###########################################################################################\n",
    "'''\n",
    "# prepare a text file with list of source documents\n",
    "file_path = './sources.txt'\n",
    "with open(file_path, 'w') as file:\n",
    "\tfile.write(\"Hello, this is a new text file created using open() function.\")\n",
    "\t\n",
    "print(f\"File '{file_path}' created successfully.\")\n",
    "'''\n",
    "###########################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.core.indices.loading:Loading all indices.\n",
      "Loading all indices.\n"
     ]
    }
   ],
   "source": [
    "# load the existing index\n",
    "PERSIST_DIR = './storage-dt'\n",
    "storage_context = StorageContext.from_defaults(persist_dir=PERSIST_DIR)\n",
    "index = load_index_from_storage(storage_context)\n",
    "nodes = list(index.docstore.docs.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hybrid retrieval\n",
    "vector_retriever = pdf_index.as_retriever(\n",
    "    similarity_top_k=5\n",
    ")\n",
    "\n",
    "bm25_retriever = BM25Retriever.from_defaults(\n",
    "    nodes=nodes,\n",
    "    similarity_top_k=5\n",
    ")\n",
    "\n",
    "class Hybridretriever(BaseRetriever):\n",
    "    def __init__(self, vector_retriever, bm25_retriever):\n",
    "        self.vector_retriever = vector_retriever\n",
    "        self.bm25_retriever = bm25_retriever\n",
    "        super().__init__()\n",
    "\n",
    "    def _retrieve(self, query, **kwargs):\n",
    "        bm25_nodes = self.bm25_retriever.retrieve(query, **kwargs)\n",
    "        vector_nodes = self.vector_retriever.retrieve(query, **kwargs)\n",
    "\n",
    "        # combine the two lists of nodes\n",
    "        all_nodes = []\n",
    "        node_ids = set()\n",
    "        for n in bm25_nodes + vector_nodes:\n",
    "            if n.node_id not in node_ids:\n",
    "                all_nodes.append(n)\n",
    "                node_ids.add(n.node_id)\n",
    "        \n",
    "        return all_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrievers\n",
    "pdf_index.as_retriever(similarity_top_k=3)\n",
    "hybrid_retriever = Hybridretriever(vector_retriever, bm25_retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-ranker\n",
    "reranker = SentenceTransformerRerank(\n",
    "    top_n=3,\n",
    "    model='BAAI/bge-reranker-base'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------\n",
    "\n",
    "\n",
    "------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Financial and operational highlights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = '''\n",
    "Outline the financial and operational highlights of Meta for Q3:2023, i.e. 3 months ending Dec. 31, 2023 and full year 2023 from the source documents./\n",
    "Include all the important details like revenue, profits, share prices, user base, etc. Strictly ensure that your response is factually correct and relevant./\n",
    "Cite the relevant sections from the source documents, so that the response is trustworthy and credible. Cross-check and refine your response, if needed./\n",
    "Your response must not contain any information that is not present in the source document. Structure your output as a paragraph under 300 words./\n",
    "FOLLOW ALL THE INSTRUCTIONS GIVEN ABOVE VERY CAREFULLY.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c583ddb4f20c4093a78732e655e7baba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# retrieval and reranking of nodes\n",
    "retrieved_nodes = hybrid_retriever.retrieve(prompt)\n",
    "\n",
    "reranked_nodes = reranker.postprocess_nodes(\n",
    "    retrieved_nodes,\n",
    "    query_bundle=QueryBundle(prompt)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Node ID:** b60f5250-00f8-4330-b947-c8bf6696a886<br>**Similarity:** 0.5963371396064758<br>**Text:** Meta Reports Fourth Quarter and Full Year 2023 Results; Initiates Quarterly Dividend\n",
       "MENLO PARK, ...<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 72f78825-ab45-4d30-8106-07228b6ff809<br>**Similarity:** 0.09835785627365112<br>**Text:** META PLATFORMS, INC.\n",
       "CONDENSED CONSOLIDATED STATEMENTS OF INCOME\n",
       "(In millions, except per share a...<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 7931d0dd-16ad-40e0-9312-56e323e99270<br>**Similarity:** 0.08390882611274719<br>**Text:** META PLATFORMS, INC.\n",
       "CONDENSED CONSOLIDATED STATEMENTS OF CASH FLOWS\n",
       "(In millions)\n",
       "(Unaudited)\n",
       "Th...<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# source nodes\n",
    "for node in reranked_nodes:\n",
    "    display_source_node(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtering out irrelevant nodes\n",
    "filter = SimilarityPostprocessor(\n",
    "    similarity_cutoff=0.1\n",
    ")\n",
    "filtered_nodes = filter.postprocess_nodes(\n",
    "    reranked_nodes,\n",
    "    query_bundle=QueryBundle(prompt)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Node ID:** b60f5250-00f8-4330-b947-c8bf6696a886<br>**Similarity:** 0.5963371396064758<br>**Text:** Meta Reports Fourth Quarter and Full Year 2023 Results; Initiates Quarterly Dividend\n",
       "MENLO PARK, ...<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# source nodes\n",
    "for node in filtered_nodes:\n",
    "    display_source_node(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query engine\n",
    "query_engine = RetrieverQueryEngine.from_args(\n",
    "    retriever=hybrid_retriever,\n",
    "    node_postprocessors=[reranker, filter],\n",
    "    llm=llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f3753254a1d4ae1a4c7989d82561a37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   60105.15 ms\n",
      "llama_print_timings:      sample time =     191.96 ms /   764 runs   (    0.25 ms per token,  3980.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =   26646.43 ms /   203 tokens (  131.26 ms per token,     7.62 tokens per second)\n",
      "llama_print_timings:        eval time =  278085.64 ms /   763 runs   (  364.46 ms per token,     2.74 tokens per second)\n",
      "llama_print_timings:       total time =  307442.20 ms /   966 tokens\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**`Final Response:`** Based on the provided source document, Meta Platforms Inc. (Meta) reported its financial and operational highlights for Q3:2023 and full year 2023.\n",
       "For Q3:2023, Meta's revenue was $40,111 million, a 25% increase year-over-year. The company's costs and expenses were $23,727 million, a decrease of 8% year-over-year. As a result, Meta's income from operations was $16,384 million, a 156% increase year-over-year. The company's operating margin was 41%, up from 20% in the same period last year.\n",
       "For full year 2023, Meta's revenue was $134,902 million, a 16% increase year-over-year. The company's costs and expenses were $88,151 million, a decrease of 1% year-over-year. As a result, Meta's income from operations was $46,751 million, a 62% increase year-over-year. The company's operating margin was 35%, up from 25% in the same period last year.\n",
       "In terms of user base, Meta reported that its family daily active people (DAP) was 3.19 billion on average for December 2023, an increase of 8% year-over-year. Its family monthly active people (MAP) was 3.98 billion as of December 31, 2023, an increase of 6% year-over-year. Its Facebook daily active users (DAUs) were 2.11 billion on average for December 2023, an increase of 6% year-over-year. Its Facebook monthly active users (MAUs) were 3.07 billion as of December 31, 2023, an increase of 3% year-over-year.\n",
       "In terms of ad impressions and price per ad, Meta reported that ad impressions delivered across its Family of Apps increased by 21% year-over-year in Q3:2023, and the average price per ad increased by 2% year-over-year. For full year 2023, ad impressions increased by 28% year-over-year and the average price per ad decreased by 9% year-over-year.\n",
       "References:\n",
       "According to Meta's Q3:2023 earnings report (p. 11):\n",
       "\"Revenue increased 25% to $40,111 million, driven by growth in ad revenue, which increased 21% to $21,334 million. Family DAUs increased 8% to 3.19 billion, and Family MAP increased 6% to 3.98 billion.\"\n",
       "According to Meta's full year 2023 earnings report (p. 11):\n",
       "\"Revenue increased 16% to $134,902 million, driven by growth in ad revenue, which increased 28% to $56,577 million. Family DAUs increased 3% to 3.07 billion, and Family MAP increased 6% to 3.98 billion.\""
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**`Source Node 1/1`**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** b60f5250-00f8-4330-b947-c8bf6696a886<br>**Similarity:** 0.5963371396064758<br>**Text:** Meta Reports Fourth Quarter and Full Year 2023 Results; Initiates Quarterly Dividend\n",
       "MENLO PARK, ...<br>**Metadata:** {'total_pages': 11, 'file_path': 'D:\\\\0-VARAD-DESHMUKH\\\\Files\\\\data\\\\q3-2023.pdf', 'source': '1'}<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# response generation\n",
    "response = query_engine.query(prompt)\n",
    "\n",
    "display_response(\n",
    "    response=response,\n",
    "    show_source=True,\n",
    "    show_source_metadata=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Risk factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = '''\n",
    "Present an overview of the risk factors faced by Meta, according to the source documents. Focus on all the risk factors like the risk factors related to product offerings,/\n",
    "market conditions, geopolitical conditions, global economic scenario, competition, technological innovations, reducing user base, etc./\n",
    "USE INFORMATION GIVEN ONLY IN THE SOURCE DOCUMENTS AND NOT PRIOR KNOWLEDGE. YOU HAVE TO CITE THE RELEVANT SECTIONS AND THEIR PAGE NUMBERS AT THE END OF THE RESPONSE./\n",
    "Cross-check and refine your response, if needed. Structure your output as a paragraph under 500 words. FOLLOW ALL THE INSTRUCTIONS GIVEN ABOVE VERY CAREFULLY.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62ac64f214a3441e8c9f81f340e27fd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** aead5a62-b58d-4393-8d6f-8850e7b57d42<br>**Similarity:** 0.8936010003089905<br>**Text:** It is not possible for our management to\n",
       "predict all risks, nor can we assess the impact of all f...<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 8b98fbed-e1a3-463e-b60f-253fa0d64b84<br>**Similarity:** 0.7181341052055359<br>**Text:** Meta Platforms, Inc.\n",
       "Form 10-K\n",
       "TABLE OF CONTENTS\n",
       "Page\n",
       "Note About Forward-Looking Statements\n",
       "3\n",
       "Lim...<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 0d1d1c9a-14ab-4cc0-85b9-5897bff6e2ab<br>**Similarity:** 0.5528134703636169<br>**Text:** Table of Contents\n",
       "Item 1A. Risk Factors\n",
       "Certain factors may have a material adverse effect on our...<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# retrieval and reranking of nodes\n",
    "retrieved_nodes = hybrid_retriever.retrieve(prompt)\n",
    "\n",
    "reranked_nodes = reranker.postprocess_nodes(\n",
    "    retrieved_nodes,\n",
    "    query_bundle=QueryBundle(prompt)\n",
    ")\n",
    "\n",
    "# reranked source nodes\n",
    "for node in reranked_nodes:\n",
    "    display_source_node(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Node ID:** aead5a62-b58d-4393-8d6f-8850e7b57d42<br>**Similarity:** 0.8936010003089905<br>**Text:** It is not possible for our management to\n",
       "predict all risks, nor can we assess the impact of all f...<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 8b98fbed-e1a3-463e-b60f-253fa0d64b84<br>**Similarity:** 0.7181341052055359<br>**Text:** Meta Platforms, Inc.\n",
       "Form 10-K\n",
       "TABLE OF CONTENTS\n",
       "Page\n",
       "Note About Forward-Looking Statements\n",
       "3\n",
       "Lim...<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 0d1d1c9a-14ab-4cc0-85b9-5897bff6e2ab<br>**Similarity:** 0.5528134703636169<br>**Text:** Table of Contents\n",
       "Item 1A. Risk Factors\n",
       "Certain factors may have a material adverse effect on our...<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# filtering out irrelevant nodes\n",
    "filter = SimilarityPostprocessor(\n",
    "    similarity_cutoff=0.1\n",
    ")\n",
    "filtered_nodes = filter.postprocess_nodes(\n",
    "    reranked_nodes,\n",
    "    query_bundle=QueryBundle(prompt)\n",
    ")\n",
    "\n",
    "# filtered source nodes\n",
    "for node in filtered_nodes:\n",
    "    display_source_node(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0584929e77b141339e16aa16caa9369e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   60105.15 ms\n",
      "llama_print_timings:      sample time =     211.49 ms /   796 runs   (    0.27 ms per token,  3763.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =   96445.06 ms /   893 tokens (  108.00 ms per token,     9.26 tokens per second)\n",
      "llama_print_timings:        eval time =  282669.50 ms /   795 runs   (  355.56 ms per token,     2.81 tokens per second)\n",
      "llama_print_timings:       total time =  382158.06 ms /  1688 tokens\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**`Final Response:`** Based on the provided source documents, there are several risk factors that Meta faces. Firstly, there is a risk related to product offerings, where Meta's products may not continue to be popular or may not be able to compete effectively with other products in the market. According to page 3 of the source document, \"We face intense competition in each of our product areas, and if we do not continue to innovate and improve our products, we may lose users to our competitors.\" This highlights the risk that Meta's products may not be able to maintain their market share, which could have a material adverse effect on the company's business, financial condition, and results of operations.\n",
       "Another risk factor is related to market conditions, where changes in market conditions may affect Meta's business. According to page 15 of the source document, \"We face risks related to changes in global economic conditions, including a slowdown in global economic growth, which could affect our revenue and profitability.\" This highlights the risk that changes in market conditions may lead to a decline in demand for Meta's products, which could have a material adverse effect on the company's business.\n",
       "Geopolitical conditions are also a risk factor for Meta. According to page 16 of the source document, \"We face risks related to changes in laws, regulations, and government policies, including those related to data privacy, data localization, and censorship.\" This highlights the risk that changes in geopolitical conditions may lead to increased regulatory scrutiny and compliance costs for Meta, which could have a material adverse effect on the company's business.\n",
       "In addition, competition is a significant risk factor for Meta. According to page 17 of the source document, \"We face intense competition in each of our product areas, and if we do not continue to innovate and improve our products, we may lose users to our competitors.\" This highlights the risk that Meta may face increased competition from other companies in the technology industry, which could lead to a decline in its market share and have a material adverse effect on its business.\n",
       "Furthermore, technological innovations may also pose a risk to Meta. According to page 18 of the source document, \"We face risks related to technological changes, including advancements in artificial intelligence, machine learning, and other technologies.\" This highlights the risk that technological innovations may make Meta's products less competitive or obsolete, which could have a material adverse effect on its business.\n",
       "Moreover, reducing user base is also a risk factor for Meta. According to page 19 of the source document, \"We face risks related to our user base, including decreases in user engagement or retention.\" This highlights the risk that Meta may face a decline in its user base, which could have a material adverse effect on its business.\n",
       "Finally, global economic scenario is also a risk factor for Meta. According to page 20 of the source document, \"We face risks related to global economic conditions, including a slowdown in global economic growth.\" This highlights the risk that a decline in global economic growth may lead to a decline in demand for Meta's products, which could have a material adverse effect on its business.\n",
       "In conclusion, Meta faces several risk factors that could have a material adverse effect on its business, financial condition, and results of operations. These risk factors include product offerings, market conditions, geopolitical conditions, competition, technological innovations, reducing user base, and global economic scenario. It is important for investors to carefully consider these risk factors when making investment decisions related to Meta."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**`Source Node 1/3`**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** aead5a62-b58d-4393-8d6f-8850e7b57d42<br>**Similarity:** 0.8936010003089905<br>**Text:** It is not possible for our management to\n",
       "predict all risks, nor can we assess the impact of all f...<br>**Metadata:** {'total_pages': 208, 'file_path': 'D:\\\\0-VARAD-DESHMUKH\\\\Files\\\\data\\\\meta-10k-2023.pdf', 'source': '5'}<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**`Source Node 2/3`**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 8b98fbed-e1a3-463e-b60f-253fa0d64b84<br>**Similarity:** 0.7181341052055359<br>**Text:** Meta Platforms, Inc.\n",
       "Form 10-K\n",
       "TABLE OF CONTENTS\n",
       "Page\n",
       "Note About Forward-Looking Statements\n",
       "3\n",
       "Lim...<br>**Metadata:** {'total_pages': 208, 'file_path': 'D:\\\\0-VARAD-DESHMUKH\\\\Files\\\\data\\\\meta-10k-2023.pdf', 'source': '3'}<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**`Source Node 3/3`**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 0d1d1c9a-14ab-4cc0-85b9-5897bff6e2ab<br>**Similarity:** 0.5528134703636169<br>**Text:** Table of Contents\n",
       "Item 1A. Risk Factors\n",
       "Certain factors may have a material adverse effect on our...<br>**Metadata:** {'total_pages': 208, 'file_path': 'D:\\\\0-VARAD-DESHMUKH\\\\Files\\\\data\\\\meta-10k-2023.pdf', 'source': '25'}<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# query engine\n",
    "query_engine = RetrieverQueryEngine.from_args(\n",
    "    retriever=hybrid_retriever,\n",
    "    node_postprocessors=[reranker, filter],\n",
    "    llm=llm\n",
    ")\n",
    "\n",
    "# response generation\n",
    "response = query_engine.query(prompt)\n",
    "\n",
    "display_response(\n",
    "    response=response,\n",
    "    show_source=True,\n",
    "    show_source_metadata=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for retrieval, reranking and response generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for retrieval and reranking of source nodes, based on the query\n",
    "def retrieval_rerank(prompt):\n",
    "    '''\n",
    "    Returns the retrieved and subsequently reranked source nodes.\n",
    "    Reranking is done using the similarity scores.\n",
    "    \n",
    "    Inputs : prompt (str) = query to the engine\n",
    "    Outputs: nodes (Node) = reranked nodes\n",
    "    '''\n",
    "    \n",
    "    # retrieval\n",
    "    retrieved_nodes = hybrid_retriever.retrieve(prompt)\n",
    "    # reranking\n",
    "    reranked_nodes = reranker.postprocess_nodes(\n",
    "    retrieved_nodes,\n",
    "    query_bundle=QueryBundle(prompt))\n",
    "\n",
    "    for node in reranked_nodes:\n",
    "        display_source_node(node)\n",
    "\n",
    "    return reranked_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to filter the reranked source nodes based on a similarity threshold\n",
    "def filter_nodes(reranked_nodes, threshold=0.5):\n",
    "    '''\n",
    "    Filters the reranked source nodes, based on a similarity threshold.\n",
    "    \n",
    "    Inputs : prompt (str) = query to the engine\n",
    "    Outputs: nodes (Node) = reranked nodes\n",
    "    '''\n",
    "    # filtering out irrelevant nodes\n",
    "    filter = SimilarityPostprocessor(\n",
    "        similarity_cutoff=threshold)\n",
    "    filtered_nodes = filter.postprocess_nodes(\n",
    "        reranked_nodes,\n",
    "        query_bundle=QueryBundle(prompt))\n",
    "\n",
    "    for node in filtered_nodes:\n",
    "        display_source_node(node)\n",
    "\n",
    "    return filtered_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to print the source nodes in Markdown format\n",
    "def display_nodes(nodes):\n",
    "    '''\n",
    "    Prints the source nodes.\n",
    "    \n",
    "    Inputs : nodes (List(Node)) = source nodes\n",
    "    Outputs: reranked nodes printed in Markdown format\n",
    "    '''\n",
    "    \n",
    "    for node in nodes:\n",
    "        display_source_node(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# response generation query engine\n",
    "def build_engine(prompt, filtering=True, streaming=True, mode='refine'):\n",
    "    '''\n",
    "    Builds the query engine.\n",
    "    \n",
    "    Inputs : prompt (str) = query prompt,\n",
    "             filter=True (bool) = were the reranked nodes filtered based on a similarity threshold?\n",
    "             streaming=True (bool) = allow streaming of response?\n",
    "             mode='refine' = response mode\n",
    "                             options -> 'refine', 'compact', 'tree_summarize', 'accumulate'\n",
    "    Outputs: response\n",
    "    '''\n",
    "    if streaming==True:\n",
    "        stream=True\n",
    "    else:\n",
    "        stream=False\n",
    "\n",
    "    from llama_index.core import PromptTemplate\n",
    "\n",
    "    # customize the prompts\n",
    "    new_qa_template = (\n",
    "        \"You are an experienced financial and investment research analyst, with profound analytical capabilities.\"\n",
    "        \"Your task is to write high-quality financial and investment research reports, which are to be published by an esteemed firm, with a large user base.\"\n",
    "        \"You perform in-depth research about a company, the industry and its capabilities, in light of the current financial condition.\"\n",
    "        \"You always generate your response based on the context information from the source documents, given below, delineated by triple backticks (```) ONLY.\\n\"\n",
    "        \"-----------------------------------------------------------------------------------------------------------------------\\n\"\n",
    "        \"```{context_str}```\"\n",
    "        \"\\n-----------------------------------------------------------------------------------------------------------------------\\n\"\n",
    "        \"Given this context information. please answer the question: {query_str}\\n\"\n",
    "        \"Cite the relevant context sources that you use to answer the question. You use the numerical facts and data from the context documents to elucidate your answer.\"\n",
    "        \"YOUR RESPONSE MUST NOT INCLUDE ANY DATA THAT IS NOT PRESENT IN THE SOURCE DOCUMENTS. Your response should be credible and trustworthy.\"\n",
    "    )\n",
    "\n",
    "    new_refine_template = (\n",
    "        \"You are an profoundly experienced document curator, excellent at reviewing and refining the research articles written by financial and investment research analysts.\"\n",
    "        \"You refine the existing articles to make them excellent enough to be published in a research report.\"\n",
    "        \"The original query is as follows: {query_str}\"\n",
    "        \"-----------------------------------------------------------------------------------------------------------------------\\n\"\n",
    "        \"We have provided an existing article written by the analyst: {existing_answer}\"\n",
    "        \"-----------------------------------------------------------------------------------------------------------------------\\n\"\n",
    "        \"You have the opportunity to refine the existing article to make it even better (only if needed) with some more context given below.\\n\"\n",
    "        \"{context_msg}\"\n",
    "        \"-----------------------------------------------------------------------------------------------------------------------\\n\"\n",
    "        \"Given the new context, cross-check the original article for factual accuracy and relevance. Refine it so that it looks more professional and crisp.\"\n",
    "        \"The refined answer must be of high-quality, apt to be included in a research report. If the context isn't useful, return the original answer.\"\n",
    "        \"-----------------------------------------------------------------------------------------------------------------------\\n\"\n",
    "        \"Refined Answer:\"\n",
    "    )\n",
    "\n",
    "    new_summary_template = (\n",
    "        \"You are an experienced financial and investment research analyst, with profound analytical capabilities.\"\n",
    "        \"Your task is to summarize the financial documents given below as context, delineated by triple backticks (```), including every important detail that is relevant\"\n",
    "        \"for including in a financial and investment research report. You ONLY USE THE INFORMATION GIVEN IN THE CONTEXT AND STRICTLY AVOID HALLUCINATING ANYTHING.\"\n",
    "        \"Your summary should be in-depth and must be relevant in light of the current financial condition.\\n\"\n",
    "        \"-----------------------------------------------------------------------------------------------------------------------\\n\"\n",
    "        \"```{context_str}```\"\n",
    "        \"-----------------------------------------------------------------------------------------------------------------------\\n\"\n",
    "        \"Using the context and the summaries that you generate, AND NOT PRIOR KNOWLEDGE, answer the query.\"\n",
    "        \"Query: {query_str}\"\n",
    "        \"Answer:\" \n",
    "    )\n",
    "\n",
    "    new_qa_prompt = PromptTemplate(new_qa_template)\n",
    "    new_refine_prompt = PromptTemplate(new_refine_template)\n",
    "    new_summary_prompt = PromptTemplate(new_summary_template)\n",
    "\n",
    "    query_engine = RetrieverQueryEngine.from_args(\n",
    "        retriever=hybrid_retriever,\n",
    "        node_postprocessors=[reranker, filter] if filtering==True else [reranker],\n",
    "        response_mode=mode,\n",
    "        text_qa_template=new_qa_prompt,\n",
    "        refine_template=new_refine_prompt,\n",
    "        summary_template=new_summary_prompt,\n",
    "        llm=llm,\n",
    "        streaming=stream)\n",
    "\n",
    "    print('Query Engine ready...')\n",
    "    return query_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# response generation\n",
    "def generate_response(prompt, query_engine, streaming=True):\n",
    "    response = query_engine.query(prompt)\n",
    "\n",
    "    if streaming==True:\n",
    "        response.print_response_stream()\n",
    "        response.get_formatted_sources()\n",
    "    else:\n",
    "        display_response(\n",
    "            response=response,\n",
    "            show_source=True,\n",
    "            show_source_metadata=True)\n",
    "        \n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = 'Summarize the risk factors faced by Meta, as outlined in the source documents.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41096cd3ca844edf8d66de6858d62241",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 097fe497-eafa-468c-a07f-b555ddb48dc9<br>**Similarity:** 0.5635961890220642<br>**Text:** Additional risks and uncertainties that we are unaware of, or that we currently believe are not m...<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 8b98fbed-e1a3-463e-b60f-253fa0d64b84<br>**Similarity:** 0.1926383674144745<br>**Text:** Meta Platforms, Inc.\n",
       "Form 10-K\n",
       "TABLE OF CONTENTS\n",
       "Page\n",
       "Note About Forward-Looking Statements\n",
       "3\n",
       "Lim...<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** aead5a62-b58d-4393-8d6f-8850e7b57d42<br>**Similarity:** 0.0849183052778244<br>**Text:** It is not possible for our management to\n",
       "predict all risks, nor can we assess the impact of all f...<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "reranked_nodes = retrieval_rerank(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 097fe497-eafa-468c-a07f-b555ddb48dc9<br>**Similarity:** 0.5635961890220642<br>**Text:** Additional risks and uncertainties that we are unaware of, or that we currently believe are not m...<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "filtered_nodes = filter_nodes(\n",
    "    reranked_nodes,\n",
    "    threshold=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Engine ready...\n"
     ]
    }
   ],
   "source": [
    "engine = build_engine(prompt, filtering=True, streaming=True, mode='refine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5af6df804c2400ab9805b5e65bfb136",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   60105.15 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     1 runs   (    0.22 ms per token,  4524.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =   96318.07 ms /   857 tokens (  112.39 ms per token,     8.90 tokens per second)\n",
      "llama_print_timings:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =   96323.26 ms /   858 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Based on Meta's 2023 Form 10-K filed with the SEC, there are several risk factors that the company faces. Here are some of the key risk factors identified by the company:\n",
      "1. Competition: Meta faces intense competition from other social media platforms, messaging apps, and online advertising platforms. The company must continue to innovate and differentiate itself from its competitors to maintain its market share. According to page 3 of Meta's 10-K, \"We face intense competition in each of our core businesses, including from other social media platforms, messaging apps, and online advertising platforms.\"\n",
      "2. Regulatory Risks: Meta is subject to various domestic and foreign laws and regulations that can impact its business. The company must comply with these regulations while also advocating for policies that support its business model. According to page 15 of Meta's 10-K, \"We face various domestic and foreign laws and regulations that may impact our business, including those related to data privacy, hate speech, and misinformation.\"\n",
      "3. Privacy and Data Security Risks: Meta collects and stores vast amounts of user data, which makes it a prime target for cyber attacks and data breaches. The company must protect its users' data while also complying with privacy regulations. According to page 16 of Meta's 10-K, \"We have experienced cyber attacks and data breaches in the past, and we may experience similar incidents in the future.\"\n",
      "4. Advertising Risks: Meta's advertising business model is critical to its revenue stream. However, changes in advertising trends, such as shifts towards ad-blocking technologies, can impact its revenue. According to page 20 of Meta's 10-K, \"Advertising revenue accounts for a significant portion of our revenue, and changes in advertising trends, such as shifts towards ad-blocking technologies, could negatively impact our revenue.\"\n",
      "5. Economic Risks: Meta's business is impacted by global economic conditions, including recession, inflation, and currency fluctuations. According to page 21 of Meta's 10-K, \"Global economic conditions, including recession, inflation, and currency fluctuations, could negatively impact our revenue and profitability.\"\n",
      "6. Intellectual Property Risks: Meta relies on intellectual property rights to protect its proprietary technology. However, the company may not be able to protect its intellectual property adequately, which could impact its competitive advantage. According to page 22 of Meta's 10-K, \"We rely on intellectual property rights to protect our proprietary technology, but we may not be able to protect our intellectual property adequately.\"\n",
      "7. Tax Risks: Meta is subject to taxes in multiple jurisdictions, which can impact its profitability. According to page 23 of Meta's 10-K, \"We are subject to taxes in multiple jurisdictions, which could negatively impact our profitability.\"\n",
      "8. Employment Risks: Meta's business is heavily dependent on its ability to attract and retain top talent. However, competition for talent can be intense, and the company may not be able to attract and retain the employees it needs. According to page 24 of Meta's 10-K, \"We rely heavily on our ability to attract and retain top talent, but competition for talent can be intense.\"\n",
      "By refining the original article, we have highlighted the key risk factors faced by Meta while also providing additional context and insights. The refined article is more professional and crisp, making it suitable for inclusion in a research report."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =   60105.15 ms\n",
      "llama_print_timings:      sample time =     201.95 ms /   826 runs   (    0.24 ms per token,  4090.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =   41280.81 ms /   348 tokens (  118.62 ms per token,     8.43 tokens per second)\n",
      "llama_print_timings:        eval time =  284411.75 ms /   825 runs   (  344.74 ms per token,     2.90 tokens per second)\n",
      "llama_print_timings:       total time =  329211.27 ms /  1173 tokens\n"
     ]
    }
   ],
   "source": [
    "response = generate_response(\n",
    "    prompt,\n",
    "    query_engine=engine,\n",
    "    streaming=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = pdf_index.as_query_engine(response_mode='tree_summarize')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = engine.query('What was the revenue of Meta in Q3:2023 and full year 2023?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**`Final Response:`** According to the provided statement of income for Meta Platforms, Inc. for Q3:2023 and full year 2023, the revenue of Meta was $40,111 million for Q3:2023 and $134,902 million for full year 2023."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**`Source Node 1/2`**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** b60f5250-00f8-4330-b947-c8bf6696a886<br>**Similarity:** 0.7965127134729699<br>**Text:** Meta Reports Fourth Quarter and Full Year 2023 Results; Initiates Quarterly Dividend\n",
       "MENLO PARK, ...<br>**Metadata:** {'total_pages': 11, 'file_path': 'D:\\\\0-VARAD-DESHMUKH\\\\Files\\\\data\\\\q3-2023.pdf', 'source': '1'}<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**`Source Node 2/2`**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 72f78825-ab45-4d30-8106-07228b6ff809<br>**Similarity:** 0.7556246571345275<br>**Text:** META PLATFORMS, INC.\n",
       "CONDENSED CONSOLIDATED STATEMENTS OF INCOME\n",
       "(In millions, except per share a...<br>**Metadata:** {'total_pages': 11, 'file_path': 'D:\\\\0-VARAD-DESHMUKH\\\\Files\\\\data\\\\q3-2023.pdf', 'source': '6'}<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_response(\n",
    "    response=response,\n",
    "    show_source=True,\n",
    "    show_source_metadata=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import PromptTemplate\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "query_engine = pdf_index.as_query_engine()\n",
    "\n",
    "# define prompt viewing function\n",
    "def display_prompt_dict(prompts_dict):\n",
    "    for k, p in prompts_dict.items():\n",
    "        text_md = f\"**Prompt Key**: {k}<br>\" f\"**Text:** <br>\"\n",
    "        display(Markdown(text_md))\n",
    "        print(p.get_template())\n",
    "        display(Markdown(\"<br><br>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Prompt Key**: response_synthesizer:summary_template<br>**Text:** <br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context information from multiple sources is below.\n",
      "---------------------\n",
      "{context_str}\n",
      "---------------------\n",
      "Given the information from multiple sources and not prior knowledge, answer the query.\n",
      "Query: {query_str}\n",
      "Answer: \n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompts_dict = engine.get_prompts()\n",
    "display_prompt_dict(prompts_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import PromptTemplate\n",
    "\n",
    "# customize the prompts\n",
    "new_qa_template = (\n",
    "    \"You are an experienced financial and investment research analyst, with profound analytical capabilities.\"\n",
    "    \"Your task is to write high-quality financial and investment research reports, which are to be published by an esteemed firm, with a large user base.\"\n",
    "    \"You perform in-depth research about a company, the industry and its capabilities, in light of the current financial condition.\"\n",
    "    \"You always generate your response based on the context information from the source documents, given below, delineated by triple backticks (```) ONLY.\\n\"\n",
    "    \"-----------------------------------------------------------------------------------------------------------------------\\n\"\n",
    "    \"```{context_str}```\"\n",
    "    \"\\n-----------------------------------------------------------------------------------------------------------------------\\n\"\n",
    "    \"Given this context information. please answer the question: {query_str}\\n\"\n",
    "    \"Cite the relevant context sources that you use to answer the question. You use the numerical facts and data from the context documents to elucidate your answer.\"\n",
    "    \"YOUR RESPONSE MUST NOT INCLUDE ANY DATA THAT IS NOT PRESENT IN THE SOURCE DOCUMENTS. Your response should be credible and trustworthy.\"\n",
    ")\n",
    "\n",
    "new_refine_template = (\n",
    "    \"You are an profoundly experienced document curator, excellent at reviewing and refining the research articles written by financial and investment research analysts.\"\n",
    "    \"You refine the existing articles to make them excellent enough to be published in a research report.\"\n",
    "    \"The original query is as follows: {query_str}\"\n",
    "    \"-----------------------------------------------------------------------------------------------------------------------\\n\"\n",
    "    \"We have provided an existing article written by the analyst: {existing_answer}\"\n",
    "    \"-----------------------------------------------------------------------------------------------------------------------\\n\"\n",
    "    \"You have the opportunity to refine the existing article to make it even better (only if needed) with some more context given below.\\n\"\n",
    "    \"{context_msg}\"\n",
    "    \"-----------------------------------------------------------------------------------------------------------------------\\n\"\n",
    "    \"Given the new context, cross-check the original article for factual accuracy and relevance. Refine it so that it looks more professional and crisp.\"\n",
    "    \"The refined answer must be of high-quality, apt to be included in a research report. If the context isn't useful, return the original answer.\"\n",
    "    \"-----------------------------------------------------------------------------------------------------------------------\\n\"\n",
    "    \"Refined Answer:\"\n",
    ")\n",
    "\n",
    "new_summary_template = (\n",
    "    \"You are an experienced financial and investment research analyst, with profound analytical capabilities.\"\n",
    "    \"Your task is to summarize the financial documents given below as context, delineated by triple backticks (```), including every important detail that is relevant\"\n",
    "    \"for including in a financial and investment research report. You ONLY USE THE INFORMATION GIVEN IN THE CONTEXT AND STRICTLY AVOID HALLUCINATING ANYTHING.\"\n",
    "    \"Your summary should be in-depth and must be relevant in light of the current financial condition.\\n\"\n",
    "    \"-----------------------------------------------------------------------------------------------------------------------\\n\"\n",
    "    \"```{context_str}```\"\n",
    "    \"-----------------------------------------------------------------------------------------------------------------------\\n\"\n",
    "    \"Using the context and the summaries that you generate, AND NOT PRIOR KNOWLEDGE, answer the query.\"\n",
    "    \"Query: {query_str}\"\n",
    "    \"Answer:\" \n",
    ")\n",
    "\n",
    "new_qa_prompt = PromptTemplate(new_qa_template)\n",
    "new_refine_prompt = PromptTemplate(new_refine_template)\n",
    "new_summary_prompt = PromptTemplate(new_summary_template)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-derived_research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
