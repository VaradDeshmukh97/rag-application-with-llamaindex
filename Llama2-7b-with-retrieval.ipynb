{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1><b>RAG-Fin-GPT : An AI Tool for Financial Research and Analytics</b></h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an AI solution for performing in-depth financial research and analysis. This system is based on Retrieval-Augmented Generation (RAG), utilizing a locally run Llama2-7b-chat LLM, develoepd by Meta. This system uses completely open-source components and takes care of the data security considerations as well, by hosting everything on a local system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><b>------------    HuggingFace CLI Login and Module Imports    ------------</b></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "!huggingface-cli login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import sys\n",
    "import torch\n",
    "import nest_asyncio \n",
    "nest_asyncio.apply()\n",
    "\n",
    "from llama_index.llms import LlamaCPP\n",
    "from llama_index.llms.utils import (\n",
    "    messages_to_prompt,\n",
    "    completion_to_prompt\n",
    ")\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from llama_index.embeddings import HuggingFaceEmbedding\n",
    "\n",
    "from llama_index import (\n",
    "    ServiceContext,\n",
    "    SimpleDirectoryReader,\n",
    "    VectorStoreIndex,\n",
    "    set_global_service_context,\n",
    "    set_global_tokenizer,\n",
    "    StorageContext,\n",
    "    load_index_from_storage\n",
    ")\n",
    "\n",
    "from llama_index import download_loader\n",
    "from llama_hub.web.news import NewsArticleReader\n",
    "\n",
    "from llama_index.node_parser import SemanticSplitterNodeParser\n",
    "from llama_index.ingestion import IngestionPipeline\n",
    "\n",
    "from llama_index.retrievers.bm25_retriever import BM25Retriever\n",
    "from llama_index.core.retrievers import (\n",
    "    BaseRetriever,\n",
    "    VectorIndexRetriever\n",
    ")\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core.postprocessor import SentenceTransformerRerank\n",
    "\n",
    "from llama_index.core import QueryBundle\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "\n",
    "from llama_index.core.response.notebook_utils import (\n",
    "    display_response,\n",
    "    display_source_node,\n",
    "    display_query_and_multimodal_response\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><b>------------    Logging    ------------</b></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    stream = sys.stdout,\n",
    "    level = logging.INFO\n",
    ")\n",
    "logging.getLogger().addHandler(\n",
    "    logging.StreamHandler(\n",
    "        stream = sys.stdout\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><b>------------    Large Language Models (LLMs)    ------------</b></center>\n",
    "\n",
    "We are using locally running open-source LLMs for our system. The details are as follows.\n",
    "\n",
    "* Foundational Model : **Llama2-7b-chat**\n",
    "* Tokenizer model : **Llama2-7b-chat _(tokenizer)_**\n",
    "* Embedding model : **WhereIsAI/UAE-Large-V1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'Llama2-7b'\n",
    "model_path = r\"C:\\0-VARAD-DESHMUKH\\models\\llama-2-7b-chat.Q6_K.gguf\"\n",
    "max_new_tokens = 2048\n",
    "context_window = 4096\n",
    "\n",
    "system_prompt = '''\n",
    "You are an experienced investment and financial research analyst, who always generates responses based only on the source documents given./\n",
    "You cite the relevant source documents properly at the end of the response or in the format 'According to <source>,'. You include the numerical figures/\n",
    "from the source documents to elucidate your response, but NEVER HALLUCINATE ANY INFORMATION. If any details are missing from the source documents,/\n",
    "you explicitly state so, rather than making up the missing information. Your responses are well-cited and credible, apt to be included in research reports.'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text-generation model \"Llama2-7b\" loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 0 | VSX = 0 | \n",
      "Model metadata: {'general.name': 'LLaMA v2', 'general.architecture': 'llama', 'llama.context_length': '4096', 'llama.rope.dimension_count': '128', 'llama.embedding_length': '4096', 'llama.block_count': '32', 'llama.feed_forward_length': '11008', 'llama.attention.head_count': '32', 'tokenizer.ggml.eos_token_id': '2', 'general.file_type': '18', 'llama.attention.head_count_kv': '32', 'llama.attention.layer_norm_rms_epsilon': '0.000001', 'tokenizer.ggml.model': 'llama', 'general.quantization_version': '2', 'tokenizer.ggml.bos_token_id': '1', 'tokenizer.ggml.unknown_token_id': '0'}\n"
     ]
    }
   ],
   "source": [
    "# the model\n",
    "llm = LlamaCPP(\n",
    "    model_path = model_path,\n",
    "    temperature = 0,\n",
    "    max_new_tokens = max_new_tokens,\n",
    "    context_window = context_window,\n",
    "    generate_kwargs = {},\n",
    "    model_kwargs = {\n",
    "        'load_in_8bit' : True,\n",
    "        'n_gpu_layers' : -1\n",
    "    },\n",
    "    system_prompt=system_prompt,\n",
    "    messages_to_prompt=messages_to_prompt,\n",
    "    completion_to_prompt=completion_to_prompt,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print('Text-generation model \"Llama2-7b\" loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_model = r'meta-llama/Llama-2-7b-chat-hf'\n",
    "hf_token = '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'\n",
    "set_global_tokenizer(\n",
    "    AutoTokenizer.from_pretrained(\n",
    "        pretrained_model_name_or_path=tokenizer_model,\n",
    "        token=hf_token\n",
    "    ).encode\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding model found in cache.\n",
      "Model name:  WhereIsAI/UAE-Large-V1 \n",
      "Model Directory:  C:\\Users\\rck05\\.cache\\huggingface\\hub\\models--WhereIsAI--UAE-Large-V1\\snapshots\\82f6ace7a8954c012dd2ae05e2604fbc9007205b\n"
     ]
    }
   ],
   "source": [
    "embed_model_path = r\"C:\\Users\\rck05\\.cache\\huggingface\\hub\\models--WhereIsAI--UAE-Large-V1\\snapshots\\82f6ace7a8954c012dd2ae05e2604fbc9007205b\"\n",
    "embed_model_name = 'WhereIsAI/UAE-Large-V1'\n",
    "\n",
    "if not os.path.exists(embed_model_path):\n",
    "    embed_model = HuggingFaceEmbedding(\n",
    "        embed_model_name\n",
    "    )\n",
    "    print('Embedding model not found in cache. Downloading and creating one.!')\n",
    "else:\n",
    "    embed_model = HuggingFaceEmbedding(\n",
    "        embed_model_path\n",
    "    ) \n",
    "    print('Embedding model found in cache.')\n",
    "\n",
    "print('Model name: ', embed_model_name, '\\nModel Directory: ', embed_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><b>------------    Global Service Context    ------------</b></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global context set.\n"
     ]
    }
   ],
   "source": [
    "service_context = ServiceContext.from_defaults(\n",
    "    llm=llm,\n",
    "    embed_model=embed_model\n",
    ")\n",
    "\n",
    "set_global_service_context(service_context)\n",
    "print('Global context set.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><b>------------    Data Loading    ------------</b></center>\n",
    "\n",
    "We load the source documents into a local directory. The source documents could be:\n",
    "1. Local PDFs\n",
    "2. News Articles\n",
    "3. Websites\n",
    "4. Static HTMLs - SEC filings, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local PDFs\n",
    "\n",
    "document_directory = r\"C:\\0-VARAD-DESHMUKH\\Files\\data\"\n",
    "\n",
    "pdfs = SimpleDirectoryReader(\n",
    "    document_directory,\n",
    "    filename_as_id=True\n",
    ").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# News Articles\n",
    "\n",
    "news_articles = [\n",
    "    r'https://www.indiatvnews.com/technology/news/meta-collaborates-with-ncmec-to-extend-take-it-down-program-for-teenagers-2024-02-07-915677',\n",
    "    r'https://www.msn.com/en-in/money/news/meta-to-label-ai-generated-images-across-social-media-platforms-details-here/ar-BB1hTNrL',\n",
    "    r'https://www.msn.com/en-in/money/other/meta-announces-plans-to-combat-deepfakes-and-ai-generated-content-on-facebook-instagram-threads-ahead-of-key-elections/ar-BB1hTfPt',\n",
    "    r'https://timesofindia.indiatimes.com/gadgets-news/20-years-of-facebook-meta-added-more-than-one-tcs-in-a-day-to-its-value/articleshow/107460150.cms',\n",
    "    r'https://www.nytimes.com/2024/02/01/technology/meta-profit-report.html',\n",
    "    r'https://www.msn.com/en-in/money/markets/meta-platforms-shatters-records-with-a-196-bn-surge-in-stock-market-value/ar-BB1hMN6e',\n",
    "]\n",
    "\n",
    "news_reader = NewsArticleReader(use_nlp=False)\n",
    "news = reader.load_data(\n",
    "    news_articles\n",
    ")\n",
    "\n",
    "# change 'publish_date' metadata to string for JSON serialization\n",
    "for i in range(len(news)):\n",
    "    news[i].metadata['publish_date'] = str(news[i].metadata['publish_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Websites\n",
    "\n",
    "WholeSiteReader = download_loader('WholeSiteReader')\n",
    "\n",
    "prefix = r'https://about.meta.com'\n",
    "base_url = r'https://about.meta.com/company-info/'\n",
    "max_depth = 1\n",
    "\n",
    "scraper = WholeSiteReader(\n",
    "    prefix=prefix,\n",
    "    max_depth=max_depth\n",
    ")\n",
    "\n",
    "websites = scraper.load_data(\n",
    "    base_url=base_url\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Static htmls : SEC filings, etc.\n",
    "\n",
    "SimpleWebPageReader = download_loader('SimpleWebPageReader')\n",
    "\n",
    "urls = [\n",
    "    r'https://www.sec.gov/Archives/edgar/data/1326801/000132680124000012/meta-20231231.htm'\n",
    "]\n",
    "loader = SimpleWebPageReader()\n",
    "\n",
    "htmls = loader.load_data(\n",
    "    urls=urls\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenating all the sources into Document objects\n",
    "documents = pdfs + news + websites + htmls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><b>------------    Data Ingestion and Indexing Pipeline    ------------</b></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.indices.loading:Loading all indices.\n",
      "Loading all indices.\n",
      "Loading all indices.\n",
      "Embeddings found in cache. Loaded directly.\n"
     ]
    }
   ],
   "source": [
    "# check if storage already exists\n",
    "PERSIST_DIR = \"./storage\"\n",
    "\n",
    "if not os.path.exists(PERSIST_DIR):\n",
    "    splitter = SemanticSplitterNodeParser(\n",
    "    buffer_size=1,\n",
    "    breakpoint_percentile_threshold=95,\n",
    "    embed_model=embed_model\n",
    ")\n",
    "    \n",
    "    embedding = HuggingFaceEmbedding(embed_model_name)\n",
    "    \n",
    "    pipeline = IngestionPipeline(\n",
    "    transformations=[splitter, embedding]\n",
    ")\n",
    "    \n",
    "    nodes = pipeline.run(\n",
    "        documents=documents,\n",
    "        in_place=False,\n",
    "        show_progress=True\n",
    ")\n",
    "   \n",
    "    # load the documents and create the index\n",
    "    storage_context = StorageContext.from_defaults()\n",
    "    storage_context.docstore.add_documents(nodes)\n",
    "    index = VectorStoreIndex(\n",
    "        nodes,\n",
    "        storage_context=storage_context\n",
    "    )\n",
    "    \n",
    "    # store it for later\n",
    "    index.storage_context.persist(persist_dir=PERSIST_DIR)\n",
    "    print('Documents embedded and loaded into memory.')\n",
    "\n",
    "else:\n",
    "    # load the existing index\n",
    "    storage_context = StorageContext.from_defaults(persist_dir=PERSIST_DIR)\n",
    "    index = load_index_from_storage(storage_context)\n",
    "    print('Embeddings found in cache. Loaded directly.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hybrid retriever + reranking\n",
    "\n",
    "vector_retriever = index.as_retriever(\n",
    "    similarity_top_k=5\n",
    ")\n",
    "\n",
    "bm25_retriever = BM25Retriever.from_defaults(\n",
    "    nodes=nodes,\n",
    "    similarity_top_k=5\n",
    ")\n",
    "\n",
    "\n",
    "class Hybridretriever(BaseRetriever):\n",
    "    def __init__(self, vector_retriever, bm25_retriever):\n",
    "        self.vector_retriever = vector_retriever\n",
    "        self.bm25_retriever = bm25_retriever\n",
    "        super().__init__()\n",
    "\n",
    "    def _retrieve(self, query, **kwargs):\n",
    "        bm25_nodes = self.bm25_retriever.retrieve(query, **kwargs)\n",
    "        vector_nodes = self.vector_retriever.retrieve(query, **kwargs)\n",
    "\n",
    "        # combine the two lists of nodes\n",
    "        all_nodes = []\n",
    "        node_ids = set()\n",
    "        for n in bm25_nodes + vector_nodes:\n",
    "            if n.node_id not in node_ids:\n",
    "                all_nodes.append(n)\n",
    "                node_ids.add(n.node_id)\n",
    "        \n",
    "        return all_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrievers\n",
    "index.as_retriever(similarity_top_k=3)\n",
    "hybrid_retriever = Hybridretriever(vector_retriever, bm25_retriever)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-ranker\n",
    "reranker = SentenceTransformerRerank(\n",
    "    top_n=3,\n",
    "    model='BAAI/bge-reranker-base'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09ace396e98c4d3793927db681ba4359",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = '''\n",
    "Outline the financial and operational highlights of Meta for Q4:2023 and full year 2023 from the source documents. Include details like revenue, profits, share prices, user base, etc./\n",
    "You have to prove that your response is correct by citing the relevant sections from the source document./\n",
    "Cross-check your response for factual accuracy and correct it, if needed. Your response must not contain any information that is not present in the source document./\n",
    "Structure your output as a paragraph under 300 words. FOLLOW ALL THE INSTRUCTIONS CAREFULLY.'''\n",
    "\n",
    "retrieved_nodes = hybrid_retriever.retrieve(prompt)\n",
    "\n",
    "reranked_nodes = reranker.postprocess_nodes(\n",
    "    retrieved_nodes,\n",
    "    query_bundle=QueryBundle(prompt)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 1145afea-d203-4acc-b32f-e4e2a2a5a957<br>**Similarity:** 0.9933016300201416<br>**Text:** Meta Reports Fourth Quarter and Full Year 202 3 Results;  Initiates Quarterly Dividend\n",
       "MENLO PARK...<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 6b9bd84c-f274-492e-8fe0-575d2253abf0<br>**Similarity:** 0.9827117323875427<br>**Text:** MENLO PARK, Calif., Feb. 1, 2024 /PRNewswire/ -- Meta Platforms, Inc. (Nasdaq: META) today report...<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 3d049646-4763-4d7f-b46f-dc5d596c3f78<br>**Similarity:** 0.9552319049835205<br>**Text:** As of , we had available and authorized for repurchases. We also announced a increase in our shar...<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# source nodes\n",
    "for node in reranked_nodes:\n",
    "    display_source_node(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query engine\n",
    "query_engine = RetrieverQueryEngine.from_args(\n",
    "    retriever=hybrid_retriever,\n",
    "    node_postprocessors=[reranker],\n",
    "    llm=llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55dcc4eeb58f48559bb6b78801c9bd7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# response generation\n",
    "response = query_engine.query(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**`Final Response:`** Based on the provided source documents, here are the financial and operational highlights of Meta for Q4:2023 and full year 2023:\n",
       "For Q4:2023, Meta reported revenue of $40,111 million, a 25% increase year-over-year. The company's operating margin was 41%, and its effective tax rate was 17%. Net income was $14,017 million, a 203% increase year-over-year, and diluted earnings per share (EPS) were $5.33, a 203% increase. Family daily active people (DAP) increased by 8% year-over-year to an average of 3.19 billion for the quarter.\n",
       "For full year 2023, Meta reported revenue of $134,902 million, a 16% increase year-over-year. The company's operating margin was 35%, and its effective tax rate was 18%. Net income was $39,098 million, a 69% increase year-over-year, and diluted EPS were $14.87, a 73% increase. User base also grew with Family monthly active people (MAP) increasing by 6% year-over-year to 3.07 billion as of December 31, 2023, and Facebook daily active users (DAUs) increasing by 6% year-over-year to 2.11 billion on average for the quarter.\n",
       "In terms of costs and expenses, total expenses were $23,727 million for Q4:2023, a decrease of 8% year-over-year, and $88,151 million for full year 2023, an increase of 1% year-over-year. Restructuring charges amounted to $1.15 billion and $3.45 billion for Q4:2023 and full year 2023, respectively.\n",
       "Finally, as of December 31, 2023, Meta had $30.93 billion available and authorized for share repurchases, with an additional $50 billion increase in its share repurchase authorization announced today."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**`Source Node 1/3`**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 1145afea-d203-4acc-b32f-e4e2a2a5a957<br>**Similarity:** 0.9933016300201416<br>**Text:** Meta Reports Fourth Quarter and Full Year 202 3 Results;  Initiates Quarterly Dividend\n",
       "MENLO PARK...<br>**Metadata:** {'page_label': '1', 'file_name': 'q3-2023.pdf', 'file_path': 'C:\\\\0-VARAD-DESHMUKH\\\\Files\\\\data\\\\q3-2023.pdf', 'file_type': 'application/pdf', 'file_size': 190925, 'creation_date': '2024-02-09', 'last_modified_date': '2024-02-09', 'last_accessed_date': '2024-02-13'}<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**`Source Node 2/3`**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 6b9bd84c-f274-492e-8fe0-575d2253abf0<br>**Similarity:** 0.9827117323875427<br>**Text:** MENLO PARK, Calif., Feb. 1, 2024 /PRNewswire/ -- Meta Platforms, Inc. (Nasdaq: META) today report...<br>**Metadata:** {'title': 'Meta Reports Fourth Quarter and Full Year 2023 Results; Initiates Quarterly Dividend', 'link': 'https://www.prnewswire.com/news-releases/meta-reports-fourth-quarter-and-full-year-2023-results-initiates-quarterly-dividend-302051285.html', 'authors': [], 'language': 'en', 'description': '/PRNewswire/ -- Meta Platforms, Inc. (Nasdaq: META) today reported financial results for the quarter and full year ended December 31, 2023. \"We had a good...', 'publish_date': 'None'}<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**`Source Node 3/3`**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 3d049646-4763-4d7f-b46f-dc5d596c3f78<br>**Similarity:** 0.9552319049835205<br>**Text:** As of , we had available and authorized for repurchases. We also announced a increase in our shar...<br>**Metadata:** {'title': 'Meta Reports Fourth Quarter and Full Year 2023 Results; Initiates Quarterly Dividend', 'link': 'https://www.prnewswire.com/news-releases/meta-reports-fourth-quarter-and-full-year-2023-results-initiates-quarterly-dividend-302051285.html', 'authors': [], 'language': 'en', 'description': '/PRNewswire/ -- Meta Platforms, Inc. (Nasdaq: META) today reported financial results for the quarter and full year ended December 31, 2023. \"We had a good...', 'publish_date': 'None'}<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_response(\n",
    "    response=response,\n",
    "    show_source=True,\n",
    "    show_source_metadata=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query engine - streaming\n",
    "query_engine = RetrieverQueryEngine.from_args(\n",
    "    retriever=hybrid_retriever,\n",
    "    node_postprocessors=[reranker],\n",
    "    llm=llm,\n",
    "    streaming=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f7fb860b379413baf94436bff5f049f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Based on the provided source documents, here are the financial and operational highlights of Meta for Q4:2023 and full year 2023:\n",
      "For Q4:2023, Meta reported revenue of $40,111 million, a 25% increase year-over-year. The company's operating margin was 41%, and its effective tax rate was 17%. Net income was $14,017 million, a 203% increase year-over-year, and diluted earnings per share (EPS) were $5.33, a 203% increase. Family daily active people (DAP) increased by 8% year-over-year to an average of 3.19 billion for the quarter.\n",
      "For full year 2023, Meta reported revenue of $134,902 million, a 16% increase year-over-year. The company's operating margin was 35%, and its effective tax rate was 18%. Net income was $39,098 million, a 69% increase year-over-year, and diluted EPS were $14.87, a 73% increase. User base also grew with Family monthly active people (MAP) increasing by 6% year-over-year to 3.07 billion as of December 31, 2023, and Facebook daily active users (DAUs) increasing by 6% year-over-year to 2.11 billion on average for the quarter.\n",
      "In terms of costs and expenses, total expenses were $23,727 million for Q4:2023, a decrease of 8% year-over-year, and $88,151 million for full year 2023, an increase of 1% year-over-year. Restructuring charges amounted to $1.15 billion and $3.45 billion for Q4:2023 and full year 2023, respectively.\n",
      "Finally, as of December 31, 2023, Meta had $30.93 billion available and authorized for share repurchases, with an additional $50 billion increase in its share repurchase authorization announced today."
     ]
    }
   ],
   "source": [
    "# response generation\n",
    "response = query_engine.query(prompt)\n",
    "response.print_response_stream()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
