{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1><b>RCK-GPT : An AI Tool for Financial Research and Analytics</b></h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an AI solution for performing in-depth financial research and analysis. This system is based on Retrieval-Augmented Generation (RAG), utilizing a locally run Llama2-7b-chat LLM, develoepd by Meta. This system uses completely open-source components and takes care of the data security considerations as well, by hosting everything on a local system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><b>------------    HuggingFace CLI Login and Module Imports    ------------</b></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "!huggingface-cli login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import sys\n",
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "import nest_asyncio \n",
    "nest_asyncio.apply()\n",
    "\n",
    "from llama_index.llms import LlamaCPP\n",
    "from llama_index import (\n",
    "    ServiceContext,\n",
    "    SimpleDirectoryReader,\n",
    "    VectorStoreIndex,\n",
    "    set_global_service_context,\n",
    "    set_global_tokenizer\n",
    ")\n",
    "\n",
    "from llama_hub.web.news import NewsArticleReader\n",
    "from llama_index import download_loader\n",
    "\n",
    "\n",
    "from llama_index.embeddings import HuggingFaceEmbedding\n",
    "from llama_index.node_parser import SemanticSplitterNodeParser\n",
    "from llama_index.ingestion import IngestionPipeline\n",
    "from llama_index.query_engine import CitationQueryEngine\n",
    "#from llama_index.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><b>------------    Logging    ------------</b></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    stream = sys.stdout,\n",
    "    level = logging.INFO\n",
    ")\n",
    "logging.getLogger().addHandler(\n",
    "    logging.StreamHandler(\n",
    "        stream = sys.stdout\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><b>------------    Large Language Models (LLMs)    ------------</b></center>\n",
    "\n",
    "We are using locally running open-source LLMs for our system. The details are as follows.\n",
    "\n",
    "* Foundational Model : **Llama2-7b-chat**\n",
    "* Tokenizer model : **Llama2-7b-chat _(tokenizer)_**\n",
    "* Embedding model : **WhereIsAI/UAE-Large-V1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 0 | VSX = 0 | \n",
      "Model metadata: {'general.name': 'LLaMA v2', 'general.architecture': 'llama', 'llama.context_length': '4096', 'llama.rope.dimension_count': '128', 'llama.embedding_length': '4096', 'llama.block_count': '32', 'llama.feed_forward_length': '11008', 'llama.attention.head_count': '32', 'tokenizer.ggml.eos_token_id': '2', 'general.file_type': '18', 'llama.attention.head_count_kv': '32', 'llama.attention.layer_norm_rms_epsilon': '0.000001', 'tokenizer.ggml.model': 'llama', 'general.quantization_version': '2', 'tokenizer.ggml.bos_token_id': '1', 'tokenizer.ggml.unknown_token_id': '0'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Foundational model loaded.\n",
      "Details -\n",
      "Model name:  Llama2-7b-chat \n",
      "Model Directory:  C:\\0-VARAD-DESHMUKH\\models\\llama-2-7b-chat.Q6_K.gguf\n"
     ]
    }
   ],
   "source": [
    "model_name = 'Llama2-7b-chat'\n",
    "model_path = r\"C:\\0-VARAD-DESHMUKH\\models\\llama-2-7b-chat.Q6_K.gguf\"\n",
    "max_new_tokens = 2048\n",
    "context_window = 4096\n",
    "\n",
    "llm = LlamaCPP(\n",
    "    model_path = model_path,\n",
    "    temperature = 0,\n",
    "    max_new_tokens = max_new_tokens,\n",
    "    context_window = context_window,\n",
    "    generate_kwargs = {},\n",
    "    model_kwargs = {\n",
    "        'load_in_8bit' : True\n",
    "    }\n",
    ")\n",
    "\n",
    "tokenizer_model = r'meta-llama/Llama-2-7b-chat-hf'\n",
    "token = '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'\n",
    "set_global_tokenizer(\n",
    "    AutoTokenizer.from_pretrained(\n",
    "        tokenizer_model,\n",
    "        token = token\n",
    "    ).encode\n",
    ")\n",
    "\n",
    "print('Foundational model loaded.')\n",
    "print('Details -\\nModel name: ', model_name, '\\nModel Directory: ', model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding model found in cache.\n",
      "Details -\n",
      "Model name:  WhereIsAI/UAE-Large-V1 \n",
      "Model Directory:  C:\\Users\\rck05\\.cache\\huggingface\\hub\\models--WhereIsAI--UAE-Large-V1\\snapshots\\82f6ace7a8954c012dd2ae05e2604fbc9007205b\n"
     ]
    }
   ],
   "source": [
    "embed_model_path = r\"C:\\Users\\rck05\\.cache\\huggingface\\hub\\models--WhereIsAI--UAE-Large-V1\\snapshots\\82f6ace7a8954c012dd2ae05e2604fbc9007205b\"\n",
    "embed_model_name = 'WhereIsAI/UAE-Large-V1'\n",
    "\n",
    "if not os.path.exists(embed_model_path):\n",
    "    embed_model = HuggingFaceEmbedding(\n",
    "        embed_model_name\n",
    "    )\n",
    "    print('Embedding model not found in cache. Downloading and creating one.!')\n",
    "else:\n",
    "    embed_model = HuggingFaceEmbedding(\n",
    "        embed_model_path\n",
    "    ) \n",
    "    print('Embedding model found in cache.')\n",
    "\n",
    "print('Details -\\nModel name: ', embed_model_name, '\\nModel Directory: ', embed_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><b>------------    Global Service Context    ------------</b></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global context set.\n",
      "Foundational model:  Llama2-7b-chat\n",
      "Embedding model:  WhereIsAI/UAE-Large-V1\n"
     ]
    }
   ],
   "source": [
    "service_context = ServiceContext.from_defaults(\n",
    "    llm = llm,\n",
    "    embed_model = embed_model\n",
    ")\n",
    "\n",
    "set_global_service_context(service_context)\n",
    "print('Global context set.')\n",
    "print('Foundational model: ', model_name)\n",
    "print('Embedding model: ', embed_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><b>------------    Data Loading    ------------</b></center>\n",
    "\n",
    "We load the source documents into a local directory. The source documents could be:\n",
    "1. Local PDFs\n",
    "2. News Articles\n",
    "3. Websites\n",
    "4. Static HTMLs - SEC filings, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Local PDFs #####\n",
    "\n",
    "#document_directory = r\"C:\\0-VARAD-DESHMUKH\\Files\\data\"\n",
    "\n",
    "#pdfs = SimpleDirectoryReader(\n",
    " #   document_directory,\n",
    "  #  filename_as_id=True\n",
    "#).load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### News Articles #####\n",
    "\n",
    "news_articles = [\n",
    "    r'https://www.indiatvnews.com/technology/news/meta-collaborates-with-ncmec-to-extend-take-it-down-program-for-teenagers-2024-02-07-915677',\n",
    "    r'https://www.msn.com/en-in/money/news/meta-to-label-ai-generated-images-across-social-media-platforms-details-here/ar-BB1hTNrL',\n",
    "    r'https://www.msn.com/en-in/money/other/meta-announces-plans-to-combat-deepfakes-and-ai-generated-content-on-facebook-instagram-threads-ahead-of-key-elections/ar-BB1hTfPt',\n",
    "    r'https://timesofindia.indiatimes.com/gadgets-news/20-years-of-facebook-meta-added-more-than-one-tcs-in-a-day-to-its-value/articleshow/107460150.cms',\n",
    "    r'https://www.nytimes.com/2024/02/01/technology/meta-profit-report.html',\n",
    "    r'https://www.msn.com/en-in/money/markets/meta-platforms-shatters-records-with-a-196-bn-surge-in-stock-market-value/ar-BB1hMN6e'\n",
    "]\n",
    "\n",
    "reader = NewsArticleReader(use_nlp=False)\n",
    "\n",
    "news = reader.load_data(\n",
    "    news_articles\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(news)):\n",
    "    news[i].metadata['publish_date'] = str(news[i].metadata['publish_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visiting: https://about.fb.com/news, 0 left\n",
      "Found 255 new potential links\n",
      "Visiting: https://about.fb.com/news/, 12 left\n",
      "Found 204 new potential links\n",
      "Visiting: https://about.fb.com/news/2024/02/labeling-ai-generated-images-on-facebook-instagram-and-threads/, 11 left\n",
      "Found 225 new potential links\n",
      "Visiting: https://about.fb.com/news/2024/02/helping-teens-avoid-sextortion-scams/, 26 left\n",
      "Found 217 new potential links\n",
      "Visiting: https://about.fb.com/news/2024/01/our-work-to-help-provide-young-people-with-safe-positive-experiences/, 31 left\n",
      "Found 207 new potential links\n",
      "Visiting: https://about.fb.com/news/2024/01/investing-in-privacy/, 33 left\n",
      "Found 212 new potential links\n",
      "Visiting: https://about.fb.com/news/2023/12/metas-2023-progress-in-ai-and-mixed-reality/, 36 left\n",
      "Found 220 new potential links\n",
      "Visiting: https://about.fb.com/news/2024/01/introducing-stricter-message-settings-for-teens-on-instagram-and-facebook/, 44 left\n",
      "Found 212 new potential links\n",
      "Visiting: https://about.fb.com/news/2024/01/davos-ai-discussions/, 47 left\n",
      "Found 222 new potential links\n",
      "Visiting: https://about.fb.com/news/2024/01/doja-cat-vr-concert/, 52 left\n",
      "Found 209 new potential links\n",
      "Visiting: https://about.fb.com/news/2024/01/teen-protections-age-appropriate-experiences-on-our-apps/, 56 left\n",
      "Found 206 new potential links\n",
      "Visiting: https://about.fb.com/news/2023/12/whatsapp-view-once-voice-messages/, 56 left\n",
      "Found 207 new potential links\n",
      "Visiting: https://about.fb.com/news/page/2/?cat=26, 59 left\n",
      "Found 206 new potential links\n",
      "Visiting: https://about.fb.com/news/page/2/, 60 left\n",
      "Found 205 new potential links\n",
      "Visiting: https://about.fb.com/news, 60 left\n",
      "Visiting: https://about.fb.com/news/2023/09/building-generative-ai-features-responsibly/, 59 left\n",
      "Visiting: https://about.fb.com/news/2023/12/meta-ai-updates/, 58 left\n",
      "Visiting: https://about.fb.com/news/category/integrity-security/, 57 left\n",
      "Visiting: https://about.fb.com/news/category/technologies/meta/, 56 left\n",
      "Visiting: https://about.fb.com/news/category/public-policy/, 55 left\n",
      "Visiting: https://about.fb.com/news/tag/artificial-intelligence-and-machine-learning/, 54 left\n",
      "Visiting: https://about.fb.com/news/category/company-news/, 53 left\n",
      "Visiting: https://about.fb.com/news/category/technology-and-innovation/, 52 left\n",
      "Visiting: https://about.fb.com/news/category/data-and-privacy/, 51 left\n",
      "Visiting: https://about.fb.com/news/category/safety-and-expression/, 50 left\n",
      "Visiting: https://about.fb.com/news/tag/misinformation/, 49 left\n",
      "Visiting: https://about.fb.com/news/category/economic-opportunity/, 48 left\n",
      "Visiting: https://about.fb.com/news/category/election-integrity/, 47 left\n",
      "Visiting: https://about.fb.com/news/category/strengthening-communities/, 46 left\n",
      "Visiting: https://about.fb.com/news/tag/diversity-and-inclusion/, 45 left\n",
      "Visiting: https://about.fb.com/wp-content/uploads/2024/02/01_Rewind-Video.mp4, 44 left\n",
      "Visiting: https://about.fb.com/news/2023/02/helping-prevent-the-spread-of-young-peoples-intimate-images-online/?shareadraft=63f93fb49743b, 43 left\n",
      "Visiting: https://about.fb.com/wp-content/uploads/2024/02/02_Explainer-Animation.mp4, 42 left\n",
      "Visiting: https://about.fb.com/news/tag/safety/, 41 left\n",
      "Visiting: https://about.fb.com/news/tag/well-being/, 40 left\n",
      "Visiting: https://about.fb.com/news/2022/11/protecting-teens-and-their-privacy-on-facebook-and-instagram/, 39 left\n",
      "Visiting: https://about.fb.com/news/2023/11/lantern-program-protecting-children-online/, 38 left\n",
      "Visiting: https://about.fb.com/news/2023/02/helping-prevent-the-spread-of-young-peoples-intimate-images-online/, 37 left\n",
      "Visiting: https://about.fb.com/news/2023/04/digital-suraksha-summit-how-meta-is-creating-an-open-and-safe-internet/, 36 left\n",
      "Visiting: https://about.fb.com/news/2023/12/default-end-to-end-encryption-on-messenger/, 35 left\n",
      "Visiting: https://about.fb.com/news/2023/02/increasing-our-ads-transparency/, 34 left\n",
      "Visiting: https://about.fb.com/news/tag/privacy-matters/, 33 left\n",
      "Visiting: https://about.fb.com/news/2023/01/building-and-innovating-with-privacy-in-mind/, 32 left\n",
      "Visiting: https://about.fb.com/wp-content/uploads/2023/12/Boz-EOY-Recap_Header.mp4, 31 left\n",
      "Visiting: https://about.fb.com/wp-content/uploads/2023/12/01_NEW-IG-BACKGROUND-EDITOR.gif?resize=800%2C800, 30 left\n",
      "Visiting: https://about.fb.com/wp-content/uploads/2023/12/02_MULTIMODAL-ON-SMART-GLASSES.mp4, 29 left\n",
      "Visiting: https://about.fb.com/wp-content/uploads/2023/12/03_BOZ-MR-IMAGE.gif?resize=800%2C800, 28 left\n",
      "Visiting: https://about.fb.com/news/2023/09/meet-meta-quest-3-mixed-reality-headset/, 27 left\n",
      "Visiting: https://about.fb.com/wp-content/uploads/2023/12/04_INSERT-VISUAL_VIDEO-OF-FUN-MR-USE-CASE.gif?resize=800%2C800, 26 left\n",
      "Visiting: https://about.fb.com/news/tag/metaverse/, 25 left\n",
      "Visiting: https://about.fb.com/news/tag/ray-ban-meta-smart-glasses/, 24 left\n",
      "Visiting: https://about.fb.com/news/2023/11/meta-partners-with-hugging-face-scaleway-to-support-open-source/, 23 left\n",
      "Visiting: https://about.fb.com/news/2023/06/parental-supervision-and-teen-time-management-on-metas-apps/, 22 left\n",
      "Visiting: https://about.fb.com/news/category/technologies/facebook-app/, 21 left\n",
      "Visiting: https://about.fb.com/news/category/technologies/instagram/, 20 left\n",
      "Visiting: https://about.fb.com/news/category/product-news/, 19 left\n",
      "Visiting: https://about.fb.com/news/2020/08/how-ai-is-accelerating-mri-scans/, 18 left\n",
      "Visiting: https://about.fb.com/news/2023/07/llama-2/, 17 left\n",
      "Visiting: https://about.fb.com/wp-content/uploads/2024/01/01_Yann_Open-Source-2.mp4, 16 left\n",
      "Visiting: https://about.fb.com/news/2023/11/how-meta-is-planning-for-elections-in-2024/, 15 left\n",
      "Visiting: https://about.fb.com/wp-content/uploads/2024/01/02_NC_Clip.mp4, 14 left\n",
      "Visiting: https://about.fb.com/news/2023/12/purple-llama-safe-responsible-ai-development/, 13 left\n",
      "Visiting: https://about.fb.com/news/category/technologies/oculus/, 12 left\n",
      "Visiting: https://about.fb.com/news/tag/music/, 11 left\n",
      "Visiting: https://about.fb.com/news/tag/virtual-reality/, 10 left\n",
      "Visiting: https://about.fb.com/news/2023/01/nba-games-in-vr-on-quest/, 9 left\n",
      "Visiting: https://about.fb.com/technologies/oculus/, 8 left\n",
      "Visiting: https://about.fb.com/news/2023/01/age-appropriate-ads-for-teens/, 7 left\n",
      "Visiting: https://about.fb.com/news/2021/08/view-once-photos-and-videos-on-whatsapp/, 6 left\n",
      "Visiting: https://about.fb.com/news/category/technologies/whatsapp/, 5 left\n",
      "Visiting: https://about.fb.com/news/2023/07/video-messages-on-whatsapp/, 4 left\n",
      "Visiting: https://about.fb.com/technologies/whatsapp/, 3 left\n",
      "Visiting: https://about.fb.com/news/?cat=26, 2 left\n",
      "Visiting: https://about.fb.com/news/page/3/?cat=26, 1 left\n",
      "Visiting: https://about.fb.com/news/page/3/, 0 left\n"
     ]
    }
   ],
   "source": [
    "##### Websites #####\n",
    "\n",
    "WholeSiteReader = download_loader('WholeSiteReader')\n",
    "\n",
    "prefix = r'https://about.fb.com'\n",
    "base_url = r'https://about.fb.com/news'\n",
    "max_depth = 1\n",
    "\n",
    "scraper = WholeSiteReader(\n",
    "    prefix=prefix,\n",
    "    max_depth=max_depth\n",
    ")\n",
    "\n",
    "websites = scraper.load_data(\n",
    "    base_url=base_url\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Static htmls : SEC filings, etc. #####\n",
    "\n",
    "SimpleWebPageReader = download_loader('SimpleWebPageReader')\n",
    "\n",
    "urls = [\n",
    "    r'https://www.sec.gov/Archives/edgar/data/1326801/000132680124000012/meta-20231231.htm'\n",
    "]\n",
    "loader = SimpleWebPageReader()\n",
    "htmls = loader.load_data(\n",
    "    urls=urls\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = news + websites + htmls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "for doc in documents:\n",
    "    for key in doc.metadata.keys():\n",
    "        doc.metadata[key] = json.dumps(doc.metadata[key], default=str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><b>------------    Data Ingestion and Indexing Pipeline    ------------</b></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = SemanticSplitterNodeParser(\n",
    "    buffer_size=1,\n",
    "    breakpoint_percentile_threshold=95,\n",
    "    embed_model=embed_model\n",
    ")\n",
    "\n",
    "embedding = HuggingFaceEmbedding(embed_model_name)\n",
    "\n",
    "pipeline = IngestionPipeline(\n",
    "    transformations=[splitter, embedding]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1438f17c0dee4ffe814f8e081bab405b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing nodes:   0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9091d3a9f01946669c5e66a797d4f62f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68dd2cfd2f394b748d977a1d73c47915",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85fea9c8cc4d49beb467150379bd682a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b93f24b73f8d4d87bb239f3ad7505196",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dd88d7f22ef4384afaead405f5451f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c3acd3e85164a289b3487371add6325",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25119af53d4646699e8be65d1ef410a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3a474bd5e684ee491ab4961d365eefc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b792b44619f447d98faed5ac2fb60e96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/68 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8970c275098d419f915a326c00c9694c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6d07b6fcfc74f189d5a2b294f3d1328",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/110 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60c426428beb4269bbd23f260e9f7cdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/34 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56b277cbec304dfaa30bbb39667c64d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "017800bf57954bb59f0450c8846c1b6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a613a8f492047c0830392de5df94df2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/56 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ffcf47f04ed4a0eb3014f06e49a329d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4e697b772c34c7b835bed6e9c30d51c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "720fc3929a094efd89d3eaae969e6ce6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2915adb385d24bdba2f8b658bb225eb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cf71efa480f4a3aba2bdee73d8105ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "125137a0deaf43538df97ece473fc0e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7bc873f313444f1bea2e3417c679b61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/55 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nodes = pipeline.run(\n",
    "    documents=documents,\n",
    "    in_place=False,\n",
    "    show_progress=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of nodes derived from the source documents :  55\n"
     ]
    }
   ],
   "source": [
    "print('Total number of nodes derived from the source documents : ', len(nodes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><b>------------    Storage of Vector Embeddings    ------------</b></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Object of type datetime is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m index \u001b[38;5;241m=\u001b[39m \u001b[43mVectorStoreIndex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnews_nodes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\0-VARAD-DESHMUKH\\.venv\\Lib\\site-packages\\llama_index\\indices\\vector_store\\base.py:53\u001b[0m, in \u001b[0;36mVectorStoreIndex.__init__\u001b[1;34m(self, nodes, objects, index_struct, service_context, storage_context, use_async, store_nodes_override, insert_batch_size, show_progress, **kwargs)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_store_nodes_override \u001b[38;5;241m=\u001b[39m store_nodes_override\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_insert_batch_size \u001b[38;5;241m=\u001b[39m insert_batch_size\n\u001b[1;32m---> 53\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_struct\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_struct\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[43m    \u001b[49m\u001b[43mservice_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mservice_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     57\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobjects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobjects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\0-VARAD-DESHMUKH\\.venv\\Lib\\site-packages\\llama_index\\indices\\base.py:75\u001b[0m, in \u001b[0;36mBaseIndex.__init__\u001b[1;34m(self, nodes, objects, index_struct, storage_context, service_context, show_progress, **kwargs)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m index_struct \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     74\u001b[0m     nodes \u001b[38;5;241m=\u001b[39m nodes \u001b[38;5;129;01mor\u001b[39;00m []\n\u001b[1;32m---> 75\u001b[0m     index_struct \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_index_from_nodes\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     76\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mobjects\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[0;32m     77\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_struct \u001b[38;5;241m=\u001b[39m index_struct\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_storage_context\u001b[38;5;241m.\u001b[39mindex_store\u001b[38;5;241m.\u001b[39madd_index_struct(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_struct)\n",
      "File \u001b[1;32mc:\\0-VARAD-DESHMUKH\\.venv\\Lib\\site-packages\\llama_index\\indices\\vector_store\\base.py:274\u001b[0m, in \u001b[0;36mVectorStoreIndex.build_index_from_nodes\u001b[1;34m(self, nodes, **insert_kwargs)\u001b[0m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[0;32m    267\u001b[0m     node\u001b[38;5;241m.\u001b[39mget_content(metadata_mode\u001b[38;5;241m=\u001b[39mMetadataMode\u001b[38;5;241m.\u001b[39mEMBED) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m nodes\n\u001b[0;32m    268\u001b[0m ):\n\u001b[0;32m    269\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    270\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot build index from nodes with no content. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    271\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease ensure all nodes have content.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    272\u001b[0m     )\n\u001b[1;32m--> 274\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_index_from_nodes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minsert_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\0-VARAD-DESHMUKH\\.venv\\Lib\\site-packages\\llama_index\\indices\\vector_store\\base.py:246\u001b[0m, in \u001b[0;36mVectorStoreIndex._build_index_from_nodes\u001b[1;34m(self, nodes, **insert_kwargs)\u001b[0m\n\u001b[0;32m    244\u001b[0m     run_async_tasks(tasks)\n\u001b[0;32m    245\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 246\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_add_nodes_to_index\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    247\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex_struct\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    248\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    249\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_show_progress\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    250\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minsert_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    251\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m index_struct\n",
      "File \u001b[1;32mc:\\0-VARAD-DESHMUKH\\.venv\\Lib\\site-packages\\llama_index\\indices\\vector_store\\base.py:200\u001b[0m, in \u001b[0;36mVectorStoreIndex._add_nodes_to_index\u001b[1;34m(self, index_struct, nodes, show_progress, **insert_kwargs)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m nodes_batch \u001b[38;5;129;01min\u001b[39;00m iter_batch(nodes, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_insert_batch_size):\n\u001b[0;32m    199\u001b[0m     nodes_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_node_with_embedding(nodes_batch, show_progress)\n\u001b[1;32m--> 200\u001b[0m     new_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_vector_store\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnodes_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minsert_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    202\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_vector_store\u001b[38;5;241m.\u001b[39mstores_text \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_store_nodes_override:\n\u001b[0;32m    203\u001b[0m         \u001b[38;5;66;03m# NOTE: if the vector store doesn't store text,\u001b[39;00m\n\u001b[0;32m    204\u001b[0m         \u001b[38;5;66;03m# we need to add the nodes to the index struct and document store\u001b[39;00m\n\u001b[0;32m    205\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m node, new_id \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(nodes_batch, new_ids):\n\u001b[0;32m    206\u001b[0m             \u001b[38;5;66;03m# NOTE: remove embedding from node to avoid duplication\u001b[39;00m\n",
      "File \u001b[1;32mc:\\0-VARAD-DESHMUKH\\.venv\\Lib\\site-packages\\llama_index\\vector_stores\\simple.py:186\u001b[0m, in \u001b[0;36mSimpleVectorStore.add\u001b[1;34m(self, nodes, **add_kwargs)\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data\u001b[38;5;241m.\u001b[39membedding_dict[node\u001b[38;5;241m.\u001b[39mnode_id] \u001b[38;5;241m=\u001b[39m node\u001b[38;5;241m.\u001b[39mget_embedding()\n\u001b[0;32m    184\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data\u001b[38;5;241m.\u001b[39mtext_id_to_ref_doc_id[node\u001b[38;5;241m.\u001b[39mnode_id] \u001b[38;5;241m=\u001b[39m node\u001b[38;5;241m.\u001b[39mref_doc_id \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 186\u001b[0m metadata \u001b[38;5;241m=\u001b[39m \u001b[43mnode_to_metadata_dict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    187\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mremove_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflat_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[0;32m    188\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    189\u001b[0m metadata\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_node_content\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    190\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data\u001b[38;5;241m.\u001b[39mmetadata_dict[node\u001b[38;5;241m.\u001b[39mnode_id] \u001b[38;5;241m=\u001b[39m metadata\n",
      "File \u001b[1;32mc:\\0-VARAD-DESHMUKH\\.venv\\Lib\\site-packages\\llama_index\\vector_stores\\utils.py:53\u001b[0m, in \u001b[0;36mnode_to_metadata_dict\u001b[1;34m(node, remove_text, text_field, flat_metadata)\u001b[0m\n\u001b[0;32m     50\u001b[0m node_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membedding\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;66;03m# dump remainder of node_dict to json string\u001b[39;00m\n\u001b[1;32m---> 53\u001b[0m metadata[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_node_content\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m metadata[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_node_type\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m node\u001b[38;5;241m.\u001b[39mclass_name()\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# store ref doc id at top level to allow metadata filtering\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# kept for backwards compatibility, will consolidate in future\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\__init__.py:231\u001b[0m, in \u001b[0;36mdumps\u001b[1;34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[0;32m    226\u001b[0m \u001b[38;5;66;03m# cached encoder\u001b[39;00m\n\u001b[0;32m    227\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m skipkeys \u001b[38;5;129;01mand\u001b[39;00m ensure_ascii \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    228\u001b[0m     check_circular \u001b[38;5;129;01mand\u001b[39;00m allow_nan \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m separators \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    230\u001b[0m     default \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sort_keys \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[1;32m--> 231\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_encoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONEncoder\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\encoder.py:200\u001b[0m, in \u001b[0;36mJSONEncoder.encode\u001b[1;34m(self, o)\u001b[0m\n\u001b[0;32m    196\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m encode_basestring(o)\n\u001b[0;32m    197\u001b[0m \u001b[38;5;66;03m# This doesn't pass the iterator directly to ''.join() because the\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;66;03m# exceptions aren't as detailed.  The list call should be roughly\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;66;03m# equivalent to the PySequence_Fast that ''.join() would do.\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_one_shot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    201\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(chunks, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[0;32m    202\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(chunks)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\encoder.py:258\u001b[0m, in \u001b[0;36mJSONEncoder.iterencode\u001b[1;34m(self, o, _one_shot)\u001b[0m\n\u001b[0;32m    253\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    254\u001b[0m     _iterencode \u001b[38;5;241m=\u001b[39m _make_iterencode(\n\u001b[0;32m    255\u001b[0m         markers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault, _encoder, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindent, floatstr,\n\u001b[0;32m    256\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey_separator, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitem_separator, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msort_keys,\n\u001b[0;32m    257\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskipkeys, _one_shot)\n\u001b[1;32m--> 258\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_iterencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\encoder.py:180\u001b[0m, in \u001b[0;36mJSONEncoder.default\u001b[1;34m(self, o)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault\u001b[39m(\u001b[38;5;28mself\u001b[39m, o):\n\u001b[0;32m    162\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Implement this method in a subclass such that it returns\u001b[39;00m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;124;03m    a serializable object for ``o``, or calls the base implementation\u001b[39;00m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;124;03m    (to raise a ``TypeError``).\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    178\u001b[0m \n\u001b[0;32m    179\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 180\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mObject of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mo\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    181\u001b[0m                     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis not JSON serializable\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: Object of type datetime is not JSON serializable"
     ]
    }
   ],
   "source": [
    "index = VectorStoreIndex(nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><b>------------    Query Engine (with streaming)    ------------</b></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine(\n",
    "    streaming=True\n",
    ")\n",
    "\n",
    "def generate(prompt):\n",
    "    response = query_engine.query(prompt)\n",
    "    response.print_response_stream()\n",
    "\n",
    "    print('z' * 50)\n",
    "    \n",
    "    for i in range(len(response.source_nodes)):\n",
    "        print(response.source_nodes[i].node.get_content())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><b>------------    Prompts and Responses    ------------</b></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Based on the information provided in the source documents, the space industry is expected to experience significant growth over the next few years. According to a McKinsey report [2], the space market has grown to approximately $447 billion in 2022, up from $280 billion in 2010 and potentially reaching $1 trillion by 2030. This growth is attributed to various factors such as increasing demand for satellite-based communication services, surge in the deployment of Earth observation satellites, emergence of new players in the space industry, and renewed interest and investment in SpaceTech.\n",
      "Axiom Space [1] provides an overview of the space ecosystem and its various sectors, including satellite manufacturing, launch services, space tourism, and space-enabled capabilities and business models. The report highlights that the space industry has been experiencing significant growth due to growing demand for satellite-based communication services and a surge in the deployment of Earth observation satellites.\n",
      "Intro-act [3] provides a detailed analysis of the space startup ecosystem, including funding trends, market size, and key players. According to the report, the space industry has seen significant growth in recent years, with over 100 space startups raising more than $1 billion in funding since 2010. The report also highlights that the space industry is expected to reach $1 trillion by 2030, driven by factors such as increasing demand for satellite-based communication services and a surge in the deployment of Earth observation satellites.\n",
      "In conclusion, based on the information provided in the source documents, the space industry is expected to experience significant growth over the next few years, driven by various factors such as increasing demand for satellite-based communication services, surge in the deployment of Earth observation satellites, emergence of new players in the space industry, and renewed interest and investment in SpaceTech. The industry is expected to reach $1 trillion by 2030, with various sectors such as satellite manufacturing, launch services, space tourism, and space-enabled capabilities and business models contributing to its growth.Source 1:\n",
      "Axiom Space \n",
      " \n",
      " \n",
      " \n",
      "Intro-act.com | frank@intro-act.com | 617-454- 1088 \n",
      " 7 Industry Overview and Opportunities  \n",
      " The space ecosystem delivers value to crucial industry sectors through space-enabled capabilities and \n",
      "business models . The SpaceTech market has been experiencing significant growth in recent years due to several \n",
      "factors, such as growing demand for satellite-based communication services and a surge in the deployment of Earth \n",
      "observation satellites, which provide valuable data for applications such as weather forecasting, climate monitoring, \n",
      "agriculture, urban planning, and disaster management. This data is used by governments, research institutions, and \n",
      "businesses to make informed decisions and develop innovative solutions. Additionally, the emergence of new \n",
      "players in the space industry, including private space companies like SpaceX, Blue Origin, and Virgin Galactic, has \n",
      "brought renewed interest and investment in SpaceTech. These companies are working on ambitious projects, such \n",
      "as reusable rocket systems, satellite constellations for global Internet coverage, and plans for space tourism.  \n",
      "Chart 7: Rise of Space Startups  \n",
      " \n",
      "Source: Intro-act, Space Capital  \n",
      " A McKinsey report elaborates that the space market has grown to approximately $447 billion in 2022, up \n",
      "from $280 billion in 2010 and potentially reaching$1 trillion by 2030.\n",
      "\n",
      "Source 2:\n",
      "Axiom Space \n",
      " \n",
      " \n",
      " \n",
      "Intro-act.com | frank@intro-act.com | 617-454- 1088 \n",
      " 21 References \n",
      " \n",
      "https://www.mckinsey.com/featured-insights/sustainable-inclusive-growth/chart-of-the-day/a-giant-leap-for-the-space-\n",
      "industry \n",
      "https://www.researchandmarkets.com/report/space-launch  \n",
      "https://www.nasa.gov/press-release/nasa-sets-coverage-for-axiom-mission-2-departure-from-space-station/  \n",
      "https://economictimes.indiatimes.com/news/international/us/50-years-on-why-havent-humans-been-back-to-the-moon-\n",
      "know-here/articleshow/96232707.cms?from=mdr  \n",
      "https://www.giiresearch.com/report/moi1189874-astronaut-space-suits-market-growth-trends-covid.html  \n",
      "https://www.reddie.co.uk/2023/05/02/manufacturing-in-microgravity-a-patent-perspective-2/  \n",
      "https://cen.acs.org/pharmaceuticals/drug-development/Pharma-goes-space-drug-development/100/i40  \n",
      "https://aviationweek.com/aerospace/commercial-space/new-record-set-2022-orbital-launch-activity  \n",
      "https://techcrunch.com/2021/11/02/the-googler-who-came-to-monetize-space/#  \n",
      "https://oig.nasa.gov/docs/IG-22-005.pdf  \n",
      "https://spacenews.\n",
      "\n",
      "Source 3:\n",
      "pdf  \n",
      "https://spacenews.com/commercial-space-station-developers-seek-clarity-on-regulations/  \n",
      "https://gizmodo.com/private-space-stations-developers-unsure-regulations-1849660418  \n",
      "https://www.nationalacademies.org/documents/embed/link/LF2255DA3DD1C41C0A42D3BEF0989ACAECE3053A6A9\n",
      "B/file/DC320DAAB638051FBA0EC8C5179C6565CBD23CC17257?noSaveAs=1  \n",
      "https://www.space.com/blue-origin-orbital-reef-system-definition-review#\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = '''\n",
    "\"Present a detailed overview of how the space industry is supposed to grow over the next few years./\n",
    "Use the numerical facts given in the source documents to elucidate your answer. Limit yourself to 300 words.\"\n",
    "'''\n",
    "generate(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><b>------------    Citation Query Engine (with streaming)    ------------</b></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "Llama.generate: prefix-match hit\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " According to the provided sources, the space industry is poised for significant growth over the next few years, driven by advancements in technology and increasing demand for satellite-based services. The market size of SpaceTech has grown from $280 billion in 2010 to approximately $447 billion in 2022, and it may reach $1 trillion by 2030 [1-3]. Private space companies like SpaceX, Blue Origin, and Virgin Galactic are working on ambitious projects that could contribute to this growth [2].\n",
      "One area of growth is the development of commercial space stations. While there are regulatory challenges to overcome, developers such as Axiom Space and Blue Origin are pushing forward with plans for orbital space stations capable of supporting human life [3]. These stations will provide a platform for conducting scientific research, manufacturing, and other activities in space.\n",
      "Another area of growth is the emergence of new players in the space industry. The number of space startups has increased from 150 in 2010 to over 600 in 2022 [3], with many of these companies focusing on innovative technologies such as reusable rockets and satellite constellations for global Internet coverage.\n",
      "Finally, the growth of the space industry is also driven by advancements in technology. For instance, SpaceX is developing reusable rocket systems, while Blue Origin is planning to launch a satellite constellation for global Internet coverage [2]. These technological advancements will enable more efficient and cost-effective access to space, leading to further growth in the industry.\n",
      "In conclusion, the space industry is poised for significant growth over the next few years, driven by factors such as increased demand for satellite-based services, advancements in technology, and the emergence of new players in the space sector. The market size of SpaceTech may reach $1 trillion by 2030, with private space companies playing a crucial role in this growth.Source 1:\n",
      "Axiom Space \n",
      " \n",
      " \n",
      " \n",
      "Intro-act.com | frank@intro-act.com | 617-454- 1088 \n",
      " 7 Industry Overview and Opportunities  \n",
      " The space ecosystem delivers value to crucial industry sectors through space-enabled capabilities and \n",
      "business models . The SpaceTech market has been experiencing significant growth in recent years due to several \n",
      "factors, such as growing demand for satellite-based communication services and a surge in the deployment of Earth \n",
      "observation satellites, which provide valuable data for applications such as weather forecasting, climate monitoring, \n",
      "agriculture, urban planning, and disaster management. This data is used by governments, research institutions, and \n",
      "businesses to make informed decisions and develop innovative solutions. Additionally, the emergence of new \n",
      "players in the space industry, including private space companies like SpaceX, Blue Origin, and Virgin Galactic, has \n",
      "brought renewed interest and investment in SpaceTech. These companies are working on ambitious projects, such \n",
      "as reusable rocket systems, satellite constellations for global Internet coverage, and plans for space tourism.  \n",
      "Chart 7: Rise of Space Startups  \n",
      " \n",
      "Source: Intro-act, Space Capital  \n",
      " A McKinsey report elaborates that the space market has grown to approximately $447 billion in 2022, up \n",
      "from $280 billion in 2010 and potentially reaching$1 trillion by 2030.\n",
      "\n",
      "Source 2:\n",
      "Axiom Space \n",
      " \n",
      " \n",
      " \n",
      "Intro-act.com | frank@intro-act.com | 617-454- 1088 \n",
      " 21 References \n",
      " \n",
      "https://www.mckinsey.com/featured-insights/sustainable-inclusive-growth/chart-of-the-day/a-giant-leap-for-the-space-\n",
      "industry \n",
      "https://www.researchandmarkets.com/report/space-launch  \n",
      "https://www.nasa.gov/press-release/nasa-sets-coverage-for-axiom-mission-2-departure-from-space-station/  \n",
      "https://economictimes.indiatimes.com/news/international/us/50-years-on-why-havent-humans-been-back-to-the-moon-\n",
      "know-here/articleshow/96232707.cms?from=mdr  \n",
      "https://www.giiresearch.com/report/moi1189874-astronaut-space-suits-market-growth-trends-covid.html  \n",
      "https://www.reddie.co.uk/2023/05/02/manufacturing-in-microgravity-a-patent-perspective-2/  \n",
      "https://cen.acs.org/pharmaceuticals/drug-development/Pharma-goes-space-drug-development/100/i40  \n",
      "https://aviationweek.com/aerospace/commercial-space/new-record-set-2022-orbital-launch-activity  \n",
      "https://techcrunch.com/2021/11/02/the-googler-who-came-to-monetize-space/#  \n",
      "https://oig.nasa.gov/docs/IG-22-005.pdf  \n",
      "https://spacenews.\n",
      "\n",
      "Source 3:\n",
      "pdf  \n",
      "https://spacenews.com/commercial-space-station-developers-seek-clarity-on-regulations/  \n",
      "https://gizmodo.com/private-space-stations-developers-unsure-regulations-1849660418  \n",
      "https://www.nationalacademies.org/documents/embed/link/LF2255DA3DD1C41C0A42D3BEF0989ACAECE3053A6A9\n",
      "B/file/DC320DAAB638051FBA0EC8C5179C6565CBD23CC17257?noSaveAs=1  \n",
      "https://www.space.com/blue-origin-orbital-reef-system-definition-review#\n",
      "\n"
     ]
    }
   ],
   "source": [
    "citation_query_engine = CitationQueryEngine.from_args(\n",
    "    index,\n",
    "    citation_chunk_size=512,\n",
    "    verbose=False,\n",
    "    response_mode='refine',\n",
    "    streaming=True,\n",
    ")\n",
    "\n",
    "def generate_citations(prompt):\n",
    "    response = citation_query_engine.query(prompt)\n",
    "    response.print_response_stream()\n",
    "\n",
    "    print('z' * 50)\n",
    "    \n",
    "    for i in range(len(response.source_nodes)):\n",
    "        print(response.source_nodes[i].node.get_content())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><b>------------    Prompts and Responses    ------------</b></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        \n",
    "prompt = '''\n",
    "\"Present a detailed overview of how the space industry is supposed to grow over the next few years./\n",
    "Use the numerical facts given in the source documents to elucidate your answer. Limit yourself to 300 words.\"\n",
    "'''\n",
    "generate_citations(prompt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
