{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>The LLM</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!huggingface-cli login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import sys\n",
    "from IPython.display import Markdown, display\n",
    "from llama_index.llms import LlamaCPP\n",
    "from llama_index import ServiceContext, set_global_tokenizer, set_global_service_context\n",
    "from llama_index import SimpleDirectoryReader, VectorStoreIndex\n",
    "from llama_index.prompts import PromptTemplate\n",
    "from llama_index.embeddings import HuggingFaceEmbedding\n",
    "from transformers import AutoTokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    stream = sys.stdout,\n",
    "    level = logging.INFO\n",
    ")\n",
    "logging.getLogger().addHandler(\n",
    "    logging.StreamHandler(\n",
    "        stream = sys.stdout\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 0 | VSX = 0 | \n",
      "Model metadata: {'general.name': 'LLaMA v2', 'general.architecture': 'llama', 'llama.context_length': '4096', 'llama.rope.dimension_count': '128', 'llama.embedding_length': '4096', 'llama.block_count': '32', 'llama.feed_forward_length': '11008', 'llama.attention.head_count': '32', 'tokenizer.ggml.eos_token_id': '2', 'general.file_type': '18', 'llama.attention.head_count_kv': '32', 'llama.attention.layer_norm_rms_epsilon': '0.000001', 'tokenizer.ggml.model': 'llama', 'general.quantization_version': '2', 'tokenizer.ggml.bos_token_id': '1', 'tokenizer.ggml.unknown_token_id': '0'}\n"
     ]
    }
   ],
   "source": [
    "model_name = 'Llama2-7b-chat'\n",
    "model_path = r\"C:\\0-VARAD-DESHMUKH\\models\\llama-2-7b-chat.Q6_K.gguf\"\n",
    "max_new_tokens = 2048\n",
    "context_window = 4096\n",
    "\n",
    "llm = LlamaCPP(\n",
    "    model_path = model_path,\n",
    "    temperature = 0,\n",
    "    max_new_tokens = max_new_tokens,\n",
    "    context_window = context_window,\n",
    "    generate_kwargs = {},\n",
    "    model_kwargs = {\n",
    "        'load_in_8bit' : True\n",
    "    }\n",
    ")\n",
    "\n",
    "tokenizer_model = r'meta-llama/Llama-2-7b-chat-hf'\n",
    "token = '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'\n",
    "set_global_tokenizer(\n",
    "    AutoTokenizer.from_pretrained(\n",
    "        tokenizer_model,\n",
    "        token = token\n",
    "    ).encode\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding model found in cache.\n",
      "Details -\n",
      "Model name:  WhereIsAI/UAE-Large-V1 \n",
      "Model Directory:  C:\\Users\\rck05\\.cache\\huggingface\\hub\\models--WhereIsAI--UAE-Large-V1\\snapshots\\82f6ace7a8954c012dd2ae05e2604fbc9007205b\n"
     ]
    }
   ],
   "source": [
    "embed_model_path = r\"C:\\Users\\rck05\\.cache\\huggingface\\hub\\models--WhereIsAI--UAE-Large-V1\\snapshots\\82f6ace7a8954c012dd2ae05e2604fbc9007205b\"\n",
    "embed_model_name = 'WhereIsAI/UAE-Large-V1'\n",
    "\n",
    "if not os.path.exists(embed_model_path):\n",
    "    embed_model = HuggingFaceEmbedding(\n",
    "        embed_model_name\n",
    "    )\n",
    "    print('Embedding model not found in cache. Downloading and creating one.!')\n",
    "else:\n",
    "    embed_model = HuggingFaceEmbedding(\n",
    "        embed_model_path\n",
    "    ) \n",
    "    print('Embedding model found in cache.')\n",
    "\n",
    "print('Details -\\nModel name: ', embed_model_name, '\\nModel Directory: ', embed_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global context set.\n",
      "Foundational model:  Llama2-7b-chat\n",
      "Embedding model:  WhereIsAI/UAE-Large-V1\n"
     ]
    }
   ],
   "source": [
    "service_context = ServiceContext.from_defaults(\n",
    "    llm = llm,\n",
    "    embed_model = embed_model\n",
    ")\n",
    "\n",
    "set_global_service_context(service_context)\n",
    "print('Global context set.')\n",
    "print('Foundational model: ', model_name)\n",
    "print('Embedding model: ', embed_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#response_iter = llm.stream_complete(\"What is global warming? Give a technical answer.\")\n",
    "#for response in response_iter:\n",
    "#    print(response.delta, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = SimpleDirectoryReader(\n",
    "    r\"C:\\0-VARAD-DESHMUKH\\Files\\data\"\n",
    ").load_data()\n",
    "# create vector store index\n",
    "#index = VectorStoreIndex.from_documents(documents)\n",
    "# set up query engine\n",
    "#query_engine = index.as_query_engine(streaming=True)\n",
    "#response = query_engine.query(\"What services does Axiom Space offer?\")\n",
    "#print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.node_parser import SemanticSplitterNodeParser\n",
    "from llama_index.extractors import (\n",
    "    SummaryExtractor,\n",
    "    TitleExtractor,\n",
    "    EntityExtractor\n",
    ")\n",
    "from llama_index.ingestion import IngestionPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes too much time!!!\n",
    "#splitter = SemanticSplitterNodeParser(\n",
    " #   buffer_size=1,\n",
    "  #  breakpoint_percentile_threshold=95,\n",
    "   # embed_model=embed_model\n",
    "#)\n",
    "\n",
    "#extractor = [\n",
    " #   SummaryExtractor(\n",
    "  #      summaries=['prev', 'self', 'next'],\n",
    "   #     llm=llm\n",
    "    #),\n",
    "    #TitleExtractor(\n",
    "     #   nodes=5,\n",
    "      #  llm=llm\n",
    "    #),\n",
    "    #EntityExtractor(\n",
    "     #   prediction_threshold=0.5,\n",
    "      #  label_entities=False,\n",
    "       # device='cpu'\n",
    "    #)\n",
    "#]\n",
    "\n",
    "#pipeline = IngestionPipeline(\n",
    " #   transformations=[splitter, *extractor]\n",
    "#)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes too much of time!!!\n",
    "#nodes = pipeline.run(\n",
    " #documents=documents,\n",
    "  #in_place=False,\n",
    "   # show_progress=True\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "splitter = SemanticSplitterNodeParser(\n",
    "    buffer_size=1,\n",
    "    breakpoint_percentile_threshold=95,\n",
    "    embed_model=embed_model\n",
    ")\n",
    "\n",
    "embedding = HuggingFaceEmbedding(embed_model_name)\n",
    "\n",
    "pipeline = IngestionPipeline(\n",
    "    transformations=[splitter, embedding]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52c10845cbb34ba6a9fdfd6d6206e835",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing nodes:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b88030ca43a4323bfd7f0c999051946",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69080c0a6b144797b629c3e662ddde54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b76b6cddc16b4c3d9084c5acc170ee7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdb11d891c7b4029be9a6b05f023ffd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "741425d29e614c9cbe90f0c240870a28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b88b703f6a946a0b1a6644b08f26952",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "866f6e5fd6e241dcb3f9ccd0eb56c171",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "833b0c47d98249e4944b1e858604ad8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "960ed4f12d2041dc8b0125d2d2ef55da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fcd4485130c46f0a4be848132696be2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38f3b699b2e644ec9112511f17b31320",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86e69ec31bfd48b9a83e5c068a0e577c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b23a3db21494b37b0c78f800aaf732b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de11e36213c6499e8a235b64551c51c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64dcf37ba3b24fe5a7fb76841e91ea3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d27b09698884077a6386c79b521e44c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e24f04d3ad4d4e8ea4012b983fedaea8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "154d673ad73a455daba26781897a2ac0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38062ca28f3e4caf8f8006cd2756b8e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b32caaf4cc940d6bf6838061b9714d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77a37602775f4bef8665fc18bfed669c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26f2d2fb47d44bca9da03d27ae4abcb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/29 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7c888edd3634777b053e0865a118303",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/46 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import nest_asyncio \n",
    "nest_asyncio.apply()\n",
    "\n",
    "nodes = pipeline.run(\n",
    "    documents=documents,\n",
    "    in_place=False,\n",
    "    show_progress=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = VectorStoreIndex(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine(streaming=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Axiom Space aims to construct the world's first commercial space station by leveraging its strategic partnership with NASA and Thales Alenia Space. The company plans to build the station in phases, starting with the initial assembly of Hab One, which is scheduled to go to space in early 2026. Axiom will then continue to expand the station through additional modules, with the goal of completing the entire structure by 2028.\n",
      "To construct the station, Axiom is utilizing cutting-edge technologies and techniques, including 3D printing and robotic assembly. The company is also working closely with its partners at Thales Alenia Space to ensure that the modules are designed and built to meet the highest standards of safety and reliability.\n",
      "Axiom's approach to constructing the world's first commercial space station is unique in several ways. First, the company is focusing on creating a modular design that can be easily expanded and modified as needed. This will allow Axiom to adapt to changing customer needs and market conditions over time. Second, Axiom is prioritizing the development of in-space manufacturing capabilities, which will enable the company to produce goods and materials in microgravity. This could include everything from spacecraft components to medical devices to advanced materials for use in a variety of industries.\n",
      "Overall, Axiom Space's approach to constructing the world's first commercial space station is designed to be innovative, flexible, and scalable. By leveraging its partnerships with NASA and Thales Alenia Space, as well as its cutting-edge technologies and techniques, Axiom is poised to revolutionize the space industry and create new opportunities for human exploration and development in Low Earth Orbit.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"Explain in detail how Axiom Space is looking to construct the world's first commercial space station.\")\n",
    "response.print_response_stream()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Axiom Space \n",
      " \n",
      " \n",
      " \n",
      "Intro-act.com | frank@intro-act.com | 617-454- 1088 \n",
      " 13 space stations in the coming years. Commercial space stations have business models that accommodate \n",
      "commercial for-profit recurring activities in LEO. \n",
      " Axiom Space is working on the world’s next breakthrough innovation platform.  Axiom Space differentiates \n",
      "itself from its competitors as the only company having the advantage of connecting its modules to the International \n",
      "Space Station. Through this strategic partnership, Axiom Space will smoothly continue its research and \n",
      "manufacturing activities through the effective adoption of the hefty multinational user base of the ISS National \n",
      "Laboratory. Leveraging techniques available only in microgravity, Axiom Station will introduce people, research, and \n",
      "manufacturing, thus proliferating the growth of key industries. In order to provide a high-quality accessible platform \n",
      "to private companies and governments, Axiom is making efforts to ensure that the space station rapidly expands the \n",
      "infrastructure and solutions operating in LEO, which will contribute to research and development. Post- completion \n",
      "of preliminary and critical design reviews in collaboration with NASA, Axiom’s partners at Thales Alenia Space have \n",
      "commenced welding and machining activities for the primary structures of Axiom Station’s first module. The initially \n",
      "assembled module will take its first step in Houston for completion of its final assembly and integration. Axiom Space \n",
      "is preparing for a 2026 launch of the first section of the station. \n",
      "Chart 14: Axiom Station Exteriors \n",
      " \n",
      "Source: Intro-act, Axiom Space  \n",
      " Background:  In May 2021, NASA and Axiom Space signed an order for the first private astronaut mission \n",
      "(Axiom Mission 1) to the International Space Station.  On April 8, 2022, a SpaceX Falcon 9 rocket carrying the \n",
      "company's Crew Dragon spacecraft was launched from Kennedy Space Center in Florida with Commander Michael \n",
      "López-Alegría and Pilot Larry Connor of the U.S., and Mission Specialists Eytan Stibbe of Israel, and Mark Pathy of \n",
      "Canada aboard. \n"
     ]
    }
   ],
   "source": [
    "print(response.source_nodes[0].get_content())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
